<!--
author: W3layouts
author URL: http://w3layouts.com
License: Creative Commons Attribution 3.0 Unported
License URL: http://creativecommons.org/licenses/by/3.0/
-->
<!DOCTYPE html>
<link rel="shortcut icon" href="https://d1nhio0ox7pgb.cloudfront.net/_img/g_collection_png/standard/256x256/fire.png">
<html lang="en">
<head>
		<title>I'm SunnerLi</title>
		<!-- for-mobile-apps -->
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="keywords" content="Work Responsive web template, Bootstrap Web Templates, Flat Web Templates, Android Compatible web template, 
Smartphone Compatible web template, free webdesigns for Nokia, Samsung, LG, SonyEricsson, Motorola web design" />

    <script>
        addEventListener("load", function () {
            setTimeout(hideURLbar, 0);
        }, false);

        function hideURLbar() {
            window.scrollTo(0, 1);
        }
    </script>
	
	<!-- css files -->
    <link href="css/bootstrap.css" rel='stylesheet' type='text/css' /><!-- bootstrap css -->
    <link href="css/style.css" rel='stylesheet' type='text/css' /><!-- custom css -->
    <link href="css/fontawesome-all.css" rel="stylesheet"><!-- fontawesome css -->
	<!-- //css files -->
	
	<!-- google fonts -->
	<link href="//fonts.googleapis.com/css?family=Mukta:200,300,400,500,600,700,800&amp;subset=devanagari,latin-ext" rel="stylesheet">
	<link href="//fonts.googleapis.com/css?family=Niramit:200,200i,300,300i,400,400i,500,500i,600,600i,700,700i&amp;subset=latin-ext,thai,vietnamese" rel="stylesheet">
	<!-- //google fonts -->
	
</head>
<body>

<!-- header -->
<header class="bg-white py-1">
	<div class="container">
		<nav class="navbar navbar-expand-lg navbar-light">
			<h1>
				<!-- <a class="navbar-brand" href="index.html"><i class="fab fa-python"></i> Sunner</a> -->
			</h1>
			<!-- <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
				<span class="navbar-toggler-icon"></span>
			</button> -->

			<div class="collapse navbar-collapse" id="navbarSupportedContent">
				<ul class="navbar-nav ml-lg-4 mr-auto">
						<!-- <li class="nav-item">
							<a class="nav-link" href="index.html">Home</a>
						</li> -->

						<li class="nav-item dropdown">
							<a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
							  Paper Notes
							</a>
							<div class="dropdown-menu" aria-labelledby="navbarDropdown">
								<a class="dropdown-item" href="paper_note_2019_single.html">2019 (Single)</a>
								<a class="dropdown-item" href="about.html">2018 (Single)</a>
								<a class="dropdown-item" href="paper_note_2018_multiple.html"> 2018 (Multiple)</a>
							</div>
						</li>
						
						<li class="nav-item dropdown">
							<a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
									Repository
							</a>
							<div class="dropdown-menu" aria-labelledby="navbarDropdown">
								<a class="dropdown-item" href="project.html">Project</a>
								<a class="dropdown-item" href="paper_reimplement.html"> Paper Idea Implementation</a>
							</div>
						</li>

						<li class="nav-item dropdown">
							<a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
							  Books
							</a>
							<div class="dropdown-menu" aria-labelledby="navbarDropdown">
								<a class="dropdown-item" href="https://sunnerli.gitbooks.io/test-book/content/">Machine Learning Foundation</a>
								<a class="dropdown-item" href="https://sunnerli.gitbooks.io/test-book-also/content/">Machine Learning Technique</a>
								<a class="dropdown-item" href="https://sunnerli.gitbooks.io/prml/content/">Machine Learning (NCTU)</a>
								<a class="dropdown-item" href="https://sunnerli.gitbooks.io/test-book4/content/"> The Introduction of NLP</a>
							</div>
						</li>

						  <li class="nav-item">
							<a class="nav-link" href="contact.html">Contact</a>
						  </li>
				</ul>
				<div class="header-right">
					<!-- <a href="signin.html" class="signin mr-4"> Sign in <i class="fas fa-sign-in-alt"></i></a> -->
					<a href="index.html" class="contact">Home</a>
				</div>
			</div>
		</nav>
	</div>
</header>
<!-- //header -->

<!-- banner -->
<section class="inner-banner">
	<div class="container">
	</div>
</section>
<!-- //banner -->


<!-- about -->
<section class="about-us py-5">
	<div class="container py-md-3">
		<div class="heading mb-5">
			<h3 class="head text-center">Paper Notes</h3>
			<p class="my-3 head text-center"> æœ¬é åˆ—å‡ºäº†æˆ‘2019çœ‹épaperçš„ç›¸é—œä¸­æ–‡ç­†è¨˜ï¼Œæœ€æ–°çœ‹éçš„paperæœƒè¢«æ“ºåœ¨æ„ˆä¸Šé¢ï¼Œä½†æ¯ä¸€å€‹é …ç›®åªå’Œä¸€ç¯‡è«–æ–‡æœ‰é—œã€‚</p>
		</div>
	</div>
</section>

<!-- æ–°å¢templete -->
<!--
<section class="about-us py-5">
	<div class="container py-md-3">
		<div class="row bottom-grids">
			<div class="col-lg-7 col-md-1 px-sm-0">
				<h3 class="my-3"> </h3>       
				<p class="mb-4">   </p>        
				<a href="#">Paper</a>             
				<a href="#">Note</a>           
				<a href="#">Code</a>     
			</div>
			<div class="col-lg7 offset-sm-1 px-lg-1">
					<br></br>
					<br></br>
				<img src="https://i.imgur.com/WTrUdst.png" height=350 width=350 alt="" class="img-fluid"/>
			</div>
		</div>
	</div>
</section> -->

<!-- å¾é€™é‚Šé–‹å§‹å¾€ä¸‹æ–°å¢ -->

<section class="about-us py-5">
	<div class="container py-md-3">
		<div class="row bottom-grids">
			<div class="col-lg-7 col-md-1 px-sm-0">
				<h3 class="my-3"> ã€éš¨ç­†ã€‘Image-to-Image Translation via Group-wise Deep Whitening-and-Coloring Transformation

				</h3>       
				<p class="mb-4"> é‡å°å·²çŸ¥çš„I2Iæ–¹æ³•ï¼Œè¦æŠŠè³‡è¨Šå¾examplarè½‰ç§»åˆ°input imageï¼Œå¤§å¤šä½¿ç”¨ä¸€äº›normalizationçš„æŠ€å·§ï¼Œè­¬å¦‚AdaIN(æˆ‘çŒœæ˜¯MUNIT)ã€‚å»£ç¾©ä¾†èªªï¼Œé€™åŒ…åˆ®äº†whiteningå’Œcoloringå…©å€‹éç¨‹ï¼Œç„¶è€Œæ­¤å…©å€‹éç¨‹è¨ˆç®—éç¨‹å¾ˆè€—æ™‚ï¼Œå› æ­¤æœ¬paperæå‡ºä¸€ç¨®end-to-endçš„æ–¹æ³•ä¾†æœ‰æ•ˆç‡åœ°æ•´åˆwhiteningå’Œcoloringåˆ°I2Iä¸­ã€‚

				</p>        
				<a href="https://arxiv.org/abs/1812.09912">Paper</a>             
				<a href="https://hackmd.io/vdn8UphdTsS_nmXzDFRi8w">Note</a>              
				<a href="https://github.com/WonwoongCho/GDWCT">Code</a>              
			</div>
			<div class="col-lg7 offset-sm-1 px-lg-1">
					<br></br>
					<br></br>
				<img src="https://i.imgur.com/c1ShjdZ.png" height=350 width=350 alt="" class="img-fluid"/>
			</div>
		</div>
	</div>
</section>

<section class="about-us py-5">
	<div class="container py-md-3">
		<div class="row bottom-grids">
			<div class="col-lg-7 col-md-1 px-sm-0">
				<h3 class="my-3"> ã€éš¨ç­†ã€‘TraVeLGAN: Image-to-image Translation by Transformation Vector Learning

				</h3>       
				<p class="mb-4"> æœ¬ç¯‡æƒ³è§£æ±ºçš„å•é¡Œæ˜¯I2Iï¼Œç‰¹åˆ¥çš„æ˜¯ï¼Œä½œè€…ä¸¦æ²’æœ‰ä½¿ç”¨cycle consistencyï¼åå€’æ˜¯å¼•å…¥äº†ä¸€å€‹siamese networkä¾†é™åˆ¶latent spaceï¼Œé€™æ¨£çš„åšæ³•å¯ä»¥è®“I2Iä½œç”¨åœ¨domain gapè¼ƒå¤§çš„æƒ…æ³ä¸‹ï¼Œè€Œä¸åƒ…æ˜¯çµæ§‹é¡ä¼¼ä½†ç´‹ç†ä¸åŒçš„å ´æ™¯ã€‚

				</p>        
				<a href="https://arxiv.org/abs/1902.09631">Paper</a>             
				<a href="https://hackmd.io/dz8j1P1nTsq5l17cQZMYcQ">Note</a>              
				<a href="https://github.com/KrishnaswamyLab/travelgan">Code</a>              
			</div>
			<div class="col-lg7 offset-sm-1 px-lg-1">
					<br></br>
					<br></br>
				<img src="https://i.imgur.com/4OZ5hcU.png" height=350 width=350 alt="" class="img-fluid"/>
			</div>
		</div>
	</div>
</section>

<section class="about-us py-5">
	<div class="container py-md-3">
		<div class="row bottom-grids">
			<div class="col-lg-7 col-md-1 px-sm-0">
				<h3 class="my-3"> Towards Instance-level Image-to-Image Translation

				</h3>       
				<p class="mb-4"> ä»¥å‰åšI2Iæ–¹æ³•(MUNIT or DRIT)çš„ç¼ºé»æ˜¯ï¼Œæ“ä½œå½±åƒçš„contentï¼Œä½†åƒ…èª¿æ•´è‡³target domainçš„global styleï¼Œä¹Ÿå°±æ˜¯æ²’æœ‰é‡å°ç‰©é«”çš„è³‡è¨Šå»å¾®èª¿ï¼Œé€™æ¨£è½‰å‡ºä¾†çš„æ•ˆæœä¸ç®—ç²¾æº–ã€‚å› æ­¤æœ¬ç¯‡paperæå‡ºinstance-aware image-to-image translation (INIT)ï¼Œè®Šæˆinstance-levelçš„I2Iï¼Œå…¶å„ªé»æœ‰å…©è€…ï¼šç¬¬ä¸€ï¼Œinstance-level objective losså¯ä»¥å¹«åŠ©generatoré‡å°å¤šæ¨£ç‰©å“åšæ­£ç¢ºè½‰æ›ï¼›ç¬¬äºŒï¼ŒINITçš„styleå…·å‚™äº†spatial informationï¼Œä¸å†åƒ…æ˜¯global styleäº†ï¼

				</p>        
				<a href="https://arxiv.org/abs/1905.01744">Paper</a>             
				<a href="https://hackmd.io/S3GldHWAQFa1IaXpZpyVFA">Note</a>              
			</div>
			<div class="col-lg7 offset-sm-1 px-lg-1">
					<br></br>
					<br></br>
				<img src="https://i.imgur.com/1sRxeor.png" height=350 width=350 alt="" class="img-fluid"/>
			</div>
		</div>
	</div>
</section>

<section class="about-us py-5">
	<div class="container py-md-3">
		<div class="row bottom-grids">
			<div class="col-lg-7 col-md-1 px-sm-0">
				<h3 class="my-3"> ã€éš¨ç­†ã€‘CollaGAN: Collaborative GAN for Missing Image Data Imputation

				</h3>       
				<p class="mb-4"> æœ¬ç¯‡æƒ³è¦è§£æ±ºçš„å•é¡Œï¼Œæ˜¯åšmissing dataçš„è³‡æ–™è£œé½Šï¼Œä½œè€…æå‡ºCollaborative Generative Adversarial Network (CollaGAN)ï¼Œå°‡imputationçš„å•é¡Œè½‰æ›æˆImage-to-image translationçš„å•é¡Œä¾†è§£æ±ºã€‚

				</p>        
				<a href="https://arxiv.org/abs/1901.09764">Paper</a>             
				<a href="https://hackmd.io/6odj3PzuSwuxJWHlUZkmMg">Note</a>              
				<a href="https://github.com/jongcye/CollaGAN_CVPR">Code</a>              
			</div>
			<div class="col-lg7 offset-sm-1 px-lg-1">
					<br></br>
					<br></br>
				<img src="https://i.imgur.com/Yi1qS5t.png" height=350 width=350 alt="" class="img-fluid"/>
			</div>
		</div>
	</div>
</section>

<section class="about-us py-5">
	<div class="container py-md-3">
		<div class="row bottom-grids">
			<div class="col-lg-7 col-md-1 px-sm-0">
				<h3 class="my-3"> ã€éš¨ç­†ã€‘mixup: Beyond Empirical Risk Minimization

				</h3>       
				<p class="mb-4"> DNNé›–ç„¶å¼·å¤§ï¼Œä½†å¥¹ç¿’æ…£å»è¨˜æ†¶è¨“ç·´è³‡æ–™(overfitting)ï¼Œä¸”å°æ–¼adversarial exampleéæ–¼æ•æ„Ÿã€‚åœ¨æ­¤ç ”ç©¶ä¸­ï¼Œä½œè€…æå‡ºmixupï¼Œåœ¨è¨“ç·´æ™‚ç”¨è³‡æ–™å°çš„combinationä¾†è¨“ç·´ï¼Œlabelå’Œåœ–ç‰‡éƒ½æœ‰æ¡ç”¨æ­¤æŠ€å·§ã€‚å¯¦é©—è­‰å¯¦mixupå¯ä»¥æœ‰æ•ˆé˜²æ­¢ç¶²è·¯å»è¨˜æ†¶è¨“ç·´è³‡æ–™çš„labelï¼Œä¸”å°æ–¼adversarial exampleæœ‰æ›´å¼·æŠµæŠ—èƒ½åŠ›ã€‚

				</p>        
				<a href="https://arxiv.org/abs/1710.09412">Paper</a>             
				<a href="https://hackmd.io/-nHurryyQ0Wlo2OQLSANKA">Note</a>              
				<a href="https://github.com/facebookresearch/mixup-cifar10">Code</a>              
			</div>
			<div class="col-lg7 offset-sm-1 px-lg-1">
					<br></br>
					<br></br>
				<img src="https://i.imgur.com/lbWpZPK.png" height=350 width=350 alt="" class="img-fluid"/>
			</div>
		</div>
	</div>
</section>

<section class="about-us py-5">
	<div class="container py-md-3">
		<div class="row bottom-grids">
			<div class="col-lg-7 col-md-1 px-sm-0">
				<h3 class="my-3"> U-GAT-IT: Unsupervised Generative Attentional Networks with Adaptive Layer-Instance Normalization for Image-to-Image Translation

				</h3>       
				<p class="mb-4"> æœ¬ç¯‡paperæå‡ºä¸€å€‹æ–°çš„unsupervised I2Iæ–¹æ³•ï¼Œç¨±ç‚ºUGATITï¼Œæ¦‚å¿µæ˜¯çµåˆlearnable normalizationå’Œattention moduleï¼Œå’Œå‚³çµ±çš„I2Iä¸åŒï¼ŒUGATITå¯ä»¥é€éæ–°æå‡ºçš„AdaLINï¼Œæ‡‰ä»˜è¼ƒå¤§çš„structureã€texture changeã€‚

				</p>        
				<a href="https://arxiv.org/abs/1907.10830">Paper</a>             
				<a href="https://hackmd.io/kQQT1GqHTjSEGZ0oDnVwKw">Note</a>              
				<a href="https://github.com/taki0112/UGATIT">Code</a>              
			</div>
			<div class="col-lg7 offset-sm-1 px-lg-1">
					<br></br>
					<br></br>
				<img src="https://i.imgur.com/Y08EWMJ.png" height=350 width=350 alt="" class="img-fluid"/>
			</div>
		</div>
	</div>
</section>

<section class="about-us py-5">
	<div class="container py-md-3">
		<div class="row bottom-grids">
			<div class="col-lg-7 col-md-1 px-sm-0">
				<h3 class="my-3"> ã€éš¨ç­†ã€‘fast patch-based style transfer of arbitrary style

				</h3>       
				<p class="mb-4"> ä½œè€…æå‡ºstyle swapï¼Œç‚ºä¸€ç¨®local matchingçš„æ–¹æ³•ï¼Œä½œè€…é¡å¤–ä½¿ç”¨80000å¼µè‡ªç„¶å½±åƒè·Ÿ80000å¼µç•«ä½œä¾†è¨“ç·´inverse networkï¼Œå¯¦é©—è­‰æ˜inverse networkè·Ÿç›´æ¥ç”¨style swapåšBPå‡ºä¾†çš„æ•ˆæœå·®ä¸å¤šï¼ä¸Šåœ–æ˜¯åšå‡ºä¾†çš„æ•ˆæœã€‚

				</p>        
				<a href="https://arxiv.org/abs/1612.04337">Paper</a>             
				<a href="https://hackmd.io/0fW8et4jR4C1oIB2ta2miw">Note</a>              
				<a href="https://github.com/rtqichen/style-swap">Code</a>              
			</div>
			<div class="col-lg7 offset-sm-1 px-lg-1">
					<br></br>
					<br></br>
				<img src="https://i.imgur.com/dibAFD6.png" height=350 width=350 alt="" class="img-fluid"/>
			</div>
		</div>
	</div>
</section>

<section class="about-us py-5">
	<div class="container py-md-3">
		<div class="row bottom-grids">
			<div class="col-lg-7 col-md-1 px-sm-0">
				<h3 class="my-3"> ã€éš¨ç­†ã€‘Arbitrary Style Transfer with Style-Attentional Networks

				</h3>       
				<p class="mb-4"> æœ¬ç¯‡paperæå‡ºstyle-attentional network (SANet)ä¾†åšstyle transferï¼Œå’Œå…¶ä»–æ–¹æ³•ç›¸æ¯”ï¼Œæ›´èƒ½å°‡local style patternsåµŒå…¥åˆ°content imageçš„semantic spatial distributionä¹‹ä¸­ã€‚ä½œè€…æ›´æå‡ºidentity losså’Œmulti-level feature embeddingä¾†æ›´åŠ ç¶­æŒcontent structureã€‚

				</p>        
				<a href="https://arxiv.org/abs/1812.02342">Paper</a>             
				<a href="https://hackmd.io/MVSfC88MRsKaqpus-CriUw">Note</a>              
			</div>
			<div class="col-lg7 offset-sm-1 px-lg-1">
					<br></br>
					<br></br>
				<img src="https://i.imgur.com/wIjbDI0.png" height=350 width=350 alt="" class="img-fluid"/>
			</div>
		</div>
	</div>
</section>

<section class="about-us py-5">
	<div class="container py-md-3">
		<div class="row bottom-grids">
			<div class="col-lg-7 col-md-1 px-sm-0">
				<h3 class="my-3"> Learning Linear Transformations for Fast Arbitrary Style Transfer

				</h3>       
				<p class="mb-4"> å…ˆå‰åšä»»æ„é¢¨æ ¼è½‰æ›çš„æ¼”ç®—æ³•ï¼Œé€šå¸¸è¨ˆç®—è¤‡é›œåº¦éƒ½å¾ˆé«˜ï¼Œè€Œä¸”ä¸å®¹æ˜“æ•æ‰åˆ°ç•«é¢¨ä¹‹é–“çš„è®Šç•°æ€§ï¼Œä¹Ÿæœƒç”¢ç”Ÿä¸€äº›artifactã€‚æœ¬ç¯‡paperæå‡ºä¸€ç¨®transformation matrixçš„å½¢å¼ä¾†è§£æ±ºarbitrary style transferçš„å•é¡Œï¼Œé€™ç¨®å½ˆæ€§çš„æ¶æ§‹åœ¨è½‰æ›çš„éç¨‹ä¸­ä¹Ÿæœƒå°‡contentçµ¦ä¿ç•™ä½ã€‚

				</p>        
				<a href="https://arxiv.org/abs/1808.04537">Paper</a>             
				<a href="https://hackmd.io/M5coMnlDRoiTszkvAeZ3jA">Note</a>              
				<a href="https://github.com/sunshineatnoon/LinearStyleTransfer">Code</a>              
			</div>
			<div class="col-lg7 offset-sm-1 px-lg-1">
					<br></br>
					<br></br>
				<img src="https://i.imgur.com/FQPQnYR.png" height=350 width=350 alt="" class="img-fluid"/>
			</div>
		</div>
	</div>
</section>

<section class="about-us py-5">
	<div class="container py-md-3">
		<div class="row bottom-grids">
			<div class="col-lg-7 col-md-1 px-sm-0">
				<h3 class="my-3"> ã€éš¨ç­†ã€‘Photorealistic Style Transfer via Wavelet Transforms

				</h3>       
				<p class="mb-4"> æœ¬ç¯‡paperæå‡ºWCT2ï¼Œä¸»è¦æ¦‚å¿µæ˜¯æå‡ºä¸€å€‹wavelet corrected transferï¼Œå°‡wavelet transformè‡ªç„¶çš„åµŒå…¥åˆ°NNä¸­ï¼Œä¸¦ä¸”ä¸éœ€è¦ä»»ä½•post-processingã€‚

				</p>        
				<a href="https://arxiv.org/abs/1903.09760">Paper</a>             
				<a href="https://hackmd.io/XR_BGBsTSKWv_7VPXDuwbA">Note</a>              
				<a href="https://github.com/clovaai/WCT2">Code</a>              
			</div>
			<div class="col-lg7 offset-sm-1 px-lg-1">
					<br></br>
					<br></br>
				<img src="https://i.imgur.com/CqBkcAa.png" height=350 width=350 alt="" class="img-fluid"/>
			</div>
		</div>
	</div>
</section>

<section class="about-us py-5">
	<div class="container py-md-3">
		<div class="row bottom-grids">
			<div class="col-lg-7 col-md-1 px-sm-0">
				<h3 class="my-3"> ã€éš¨ç­†ã€‘Avatar-Net: Multi-scale Zero-shot Style Transfer by Feature Decoration

				</h3>       
				<p class="mb-4"> AvatarNetçš„é—œéµåœ¨æ–¼style decoratorï¼Œé€éä»–ä¾†å°content featureå’Œstyle featureåšalignmentã€‚ä¸Šåœ–æ˜¯Avatar-Netåšå‡ºä¾†çš„æ•ˆæœã€‚

				</p>        
				<a href="https://arxiv.org/abs/1805.03857">Paper</a>             
				<a href="https://hackmd.io/51sgpyu0SreZVKzu1nOiVw">Note</a>              
				<a href="https://github.com/LucasSheng/avatar-net">Code</a>              
			</div>
			<div class="col-lg7 offset-sm-1 px-lg-1">
					<br></br>
					<br></br>
				<img src="https://i.imgur.com/8WCJ7ks.png" height=350 width=350 alt="" class="img-fluid"/>
			</div>
		</div>
	</div>
</section>

<section class="about-us py-5">
	<div class="container py-md-3">
		<div class="row bottom-grids">
			<div class="col-lg-7 col-md-1 px-sm-0">
				<h3 class="my-3"> IntroVAE: Introspective Variational Autoencoders for Photographic Image Synthesis

				</h3>       
				<p class="mb-4"> æœ¬ç¯‡paperæå‡ºVAEçš„æ”¹è‰¯ï¼Œç¨±ç‚ºè‡ªçœè®Šåˆ†ç·¨ç¢¼å™¨ - introspective VAE (IntroVAE)ï¼Œç”¨ä¾†åšé«˜è§£æåº¦image synthesizingã€‚IntroVAEèåˆäº†VAEå’ŒGANçš„æ€æƒ³ï¼Œä½†å»æ²’æœ‰discriminatorçš„å­˜åœ¨ï¼åƒ…ä½¿ç”¨inference model (encoder)ä¾†è¾¨åˆ¥æ¨£æœ¬çš„çœŸå¯¦æ€§ï¼Œæ¸¬è©¦åœ¨CelebAä¸Šå¯ä»¥ç”¢ç”Ÿå¹¾ä¹SOTAçš„æ•ˆæœï¼

				</p>        
				<a href="https://arxiv.org/abs/1807.06358">Paper</a>             
				<a href="https://hackmd.io/N7JMgOsoSu2AEN2OGATriA">Note</a>              
				<a href="https://github.com/dragen1860/IntroVAE-Pytorch">Code</a>              
				<a href="https://github.com/SunnerLi/IntroVAE-PyTorch">My Implementation</a>
			</div>
			<div class="col-lg7 offset-sm-1 px-lg-1">
					<br></br>
					<br></br>
				<img src="https://i.imgur.com/6xXDb54.png" height=350 width=350 alt="" class="img-fluid"/>
			</div>
		</div>
	</div>
</section>

<section class="about-us py-5">
	<div class="container py-md-3">
		<div class="row bottom-grids">
			<div class="col-lg-7 col-md-1 px-sm-0">
				<h3 class="my-3"> Wasserstein Divergence for GANs

				</h3>       
				<p class="mb-4"> ç›®å‰GANä¸­WGANè¡¨ç¾çš„éå¸¸ä¸éŒ¯ï¼Œç†è«–æ¨å°ä¹Ÿå¾ˆå®Œå‚™ï¼Œç„¶è€Œåœ¨å¯¦ä½œä¸Šï¼Œå»é€¼è¿‘k-Lipschitzé€£çºŒçš„é™åˆ¶ä¾†è¿‘ä¼¼Wasserstein-1 metricæ˜¯éå¸¸æœ‰æŒ‘æˆ°æ€§çš„ï¼æœ¬paperæå‡ºWasserstein divergence (W-div)çš„æ¦‚å¿µï¼Œå¯çœ‹ä½œæ˜¯W-metçš„æ”¾å¯¬é™åˆ¶ç‰ˆæœ¬ï¼Œä¸éœ€è¦k-Lipschitzé€£çºŒçš„é™åˆ¶ã€‚

				</p>        
				<a href="https://arxiv.org/abs/1712.01026">Paper</a>             
				<a href="https://hackmd.io/IyddpCjYSc2mwXdCslaScg">Note</a>              
				<a href="https://github.com/eriklindernoren/PyTorch-GAN/blob/master/implementations/wgan_div/wgan_div.py">Code</a>              
			</div>
			<div class="col-lg7 offset-sm-1 px-lg-1">
					<br></br>
					<br></br>
				<img src="https://i.imgur.com/v0qGwis.png" height=350 width=350 alt="" class="img-fluid"/>
			</div>
		</div>
	</div>
</section>

<section class="about-us py-5">
	<div class="container py-md-3">
		<div class="row bottom-grids">
			<div class="col-lg-7 col-md-1 px-sm-0">
				<h3 class="my-3"> Improving the Improved Training of Wasserstein GANs: A Consistency Term and Its Dual Effect

				</h3>       
				<p class="mb-4"> æœ¬ç¯‡paperå¾WGANå‡ºç™¼ï¼Œæå‡ºä¸€å€‹æ–°æ–¹æ³•ï¼ŒæŠŠLipschitz continuityçš„é™åˆ¶ç¶åœ¨è¨“ç·´éç¨‹ä¸­ã€‚

				</p>        
				<a href="https://arxiv.org/abs/1803.01541">Paper</a>             
				<a href="https://hackmd.io/IPzjmspJS9SY-3IeGmV63Q">Note</a>              
				<a href="https://github.com/Randl/improved-improved-wgan-pytorch">Code</a>              
			</div>
			<div class="col-lg7 offset-sm-1 px-lg-1">
					<br></br>
					<br></br>
				<img src="https://i.imgur.com/dtoclJQ.png" height=350 width=350 alt="" class="img-fluid"/>
			</div>
		</div>
	</div>
</section>

<section class="about-us py-5">
	<div class="container py-md-3">
		<div class="row bottom-grids">
			<div class="col-lg-7 col-md-1 px-sm-0">
				<h3 class="my-3"> Variational Discriminator Bottleneck: Improving Imitation Learning, Inverse RL, and GANs by Constraining Information Flow

				</h3>       
				<p class="mb-4"> æœ¬ç¯‡paperæ˜¯æƒ³è¦æ”¹å–„GANä¸­discriminatoræœƒåé¥‹æ²’æœ‰è³‡è¨Šæ¢¯åº¦çš„è­°é¡Œï¼Œæå‡ºvariational discriminator bottleneck (VDB)ï¼Œæ¦‚å¿µæ˜¯é™åˆ¶observationå’Œdiscriminator internal representationä¹‹é–“çš„mutual informationã€‚å¯ä»¥æƒ³åƒæˆå°±æ˜¯åœ¨discriminator internal representationä¸­åŠ å™ªè²ï¼Œè®“discriminatoråˆ¥å­¸é‚£éº¼å¿«ã€‚

				</p>        
				<a href="https://arxiv.org/abs/1810.00821">Paper</a>             
				<a href="https://hackmd.io/tFc4YO8LThqdblSiJmx-6A">Note</a>              
				<a href="https://github.com/akanimax/Variational_Discriminator_Bottleneck/">Code</a>              
			</div>
			<div class="col-lg7 offset-sm-1 px-lg-1">
					<br></br>
					<br></br>
				<img src="https://i.imgur.com/3XzfmcM.png" height=350 width=350 alt="" class="img-fluid"/>
			</div>
		</div>
	</div>
</section>

<section class="about-us py-5">
	<div class="container py-md-3">
		<div class="row bottom-grids">
			<div class="col-lg-7 col-md-1 px-sm-0">
				<h3 class="my-3"> Which Training Methods for GANs do actually Converge?

				</h3>       
				<p class="mb-4"> æœ¬ç¯‡paperè«–è¿°ï¼šå°æ–¼GANè¨“ç·´ï¼Œè³‡æ–™åˆ†å¸ƒå¿…é ˆæ˜¯absolute continuityï¼Œå¦‚æœä¸æ˜¯ï¼Œå³ä½¿æ˜¯WGANé€™é¡çš„æ¨¡å‹éƒ½å¯èƒ½æœƒç„¡æ³•æ”¶æ–‚ï¼Œæ²’è¾¦æ³•èµ°åˆ°equilibrium pointã€‚ä½œè€…è¿‘ä¸€æ­¥æå‡ºä¸€ç¨®regularizationçš„ç­–ç•¥ï¼Œä¸¦è¨è«–instance noiseå’Œzero-centered gradient panaltieséƒ½å¯è®“æ”¶æ–‚ç™¼ç”Ÿã€‚ä½œè€…è­‰æ˜å³ä½¿data distributionå’Œgeneratoråˆ†å¸ƒåœ¨ä½ç¶­æµå½¢ä¸­ï¼Œç°¡å–®çš„æ·»åŠ regularization termçš„ä½œæ³•ä»èƒ½è®“GANèµ°åˆ°local convergenceï¼

				</p>        
				<a href="https://arxiv.org/abs/1801.04406">Paper</a>             
				<a href="https://hackmd.io/RtZcKioBQHihziUeqTeTpQ">Note</a>              
				<a href="https://github.com/LMescheder/GAN_stability">Code</a>              
			</div>
			<div class="col-lg7 offset-sm-1 px-lg-1">
					<br></br>
					<br></br>
				<img src="https://i.imgur.com/k7rhGhj.png" height=350 width=350 alt="" class="img-fluid"/>
			</div>
		</div>
	</div>
</section>

<section class="about-us py-5">
	<div class="container py-md-3">
		<div class="row bottom-grids">
			<div class="col-lg-7 col-md-1 px-sm-0">
				<h3 class="my-3"> [éš¨ç­†] Progressive GAN

				</h3>       
				<p class="mb-4"> åœ¨æœ¬ç¯‡paperä¸­ï¼Œä½œè€…æå‡ºprogressive growingçš„æŠ€å·§ä¾†è¨“ç·´GANï¼Œä¸¦æå‡ºä¸€ç¨®ç°¡å–®çš„æ–¹æ³•ï¼Œä¾†å¢åŠ generated imageçš„è®Šç•°æ€§ã€‚æ­¤å¤–ï¼Œä½œè€…æå‡ºä¸€äº›æŠ€å·§ï¼Œä¾†æ”¹å–„Gå’ŒDçš„ä¸å¥åº·ç«¶çˆ­é—œä¿‚ã€‚

				</p>        
				<a href="https://arxiv.org/abs/1710.10196">Paper</a>             
				<a href="https://hackmd.io/6mBPg1TMT4ac6VUvtHkGpw">Note</a>              
				<a href="https://github.com/nashory/pggan-pytorch">Code</a>              
			</div>
			<div class="col-lg7 offset-sm-1 px-lg-1">
					<br></br>
					<br></br>
				<img src="https://i.imgur.com/47dsZYw.png" height=350 width=350 alt="" class="img-fluid"/>
			</div>
		</div>
	</div>
</section>

<section class="about-us py-5">
	<div class="container py-md-3">
		<div class="row bottom-grids">
			<div class="col-lg-7 col-md-1 px-sm-0">
				<h3 class="my-3"> LIA: Latently Invertible Autoencoder with Adversarial Learning

				</h3>       
				<p class="mb-4"> æœ¬ç¯‡æƒ³åšçš„æ˜¯è·ŸPIONEERé¡ä¼¼ï¼Œåœ¨deep generative modelå­˜åœ¨è‘—å…©å€‹å•é¡Œï¼šVAEåšvariational inferenceè¡¨ç¾æ²’æœ‰å¾ˆå¥½ã€GANå‰‡æ²’æœ‰encoding sampleçš„èƒ½åŠ›ã€‚æœ¬paperæå‡ºLatently Invertible Autoencoder (LIA)ä¾†è§£æ±ºæ­¤å•é¡Œï¼Œåœ¨encoder-decoderçš„æ¶æ§‹å‘ï¼Œéš±è—äº†ä¸€å€‹deep invertible networkå’Œinverse deep invertible networkï¼Œç”¨ä¾†æŠŠfeature distributionæŠ•å°„åˆ°ä¸€å€‹ ğ‘ ä¸­ï¼Œä¸¦è¿‘ä¼¼priorã€‚two-stage stochasticity-free trainingæ˜¯è¨“ç·´LIAçš„æ–¹æ³•ã€‚å¯¦é©—è¡¨æ˜åšåœ¨FFHQä¸Šæœ‰è‘—å¾ˆå¥½çš„æ•ˆæœï¼

				</p>        
				<a href="https://arxiv.org/abs/1906.08090">Paper</a>             
				<a href="https://hackmd.io/2aVlC1yJTniqT1CIbcYsGw">Note</a>              
				<a href="https://github.com/zhujiapeng/LIA">Code</a>              
			</div>
			<div class="col-lg7 offset-sm-1 px-lg-1">
					<br></br>
					<br></br>
				<img src="https://i.imgur.com/vL90kl2.png" height=350 width=350 alt="" class="img-fluid"/>
			</div>
		</div>
	</div>
</section>

<section class="about-us py-5">
	<div class="container py-md-3">
		<div class="row bottom-grids">
			<div class="col-lg-7 col-md-1 px-sm-0">
				<h3 class="my-3"> Pioneer Networks: Progressively Growing Generative Autoencoder

				</h3>       
				<p class="mb-4"> æœ¬ç¯‡æå‡ºäº†ä¸€ç¨®æ–°ç©çš„generative autoencoderæ¨¡å‹ã€‚GANé›–ç„¶èƒ½å¤ ç”¢ç”Ÿé«˜å“è³ªåœ–åƒï¼Œä½†å»æ²’æœ‰reconstructionçš„èƒ½åŠ›ï¼›æœ¬ç¯‡èåˆäº†æœ€è¿‘è¢«æå‡ºäº†ptogressiveæŠ€å·§ï¼Œæå‡ºäº†PIONEERï¼Œåœ¨è¨“ç·´æ™‚å®Œå…¨ä¸éœ€è¦discriminatorï¼Œåœ¨CelebA inferenceçš„éƒ¨åˆ†å–å¾—äº†SOTAï¼Œå¯ä»¥æƒ³åƒæˆæ˜¯progressive + VAEåšåœ¨image generationä¸­ï¼

				</p>        
				<a href="https://arxiv.org/abs/1807.03026">Paper</a>             
				<a href="https://hackmd.io/ejyRFabEQGCVgs2GGPgOzg">Note</a>              
				<a href="https://github.com/heljakka/pioneer">Code</a>              
			</div>
			<div class="col-lg7 offset-sm-1 px-lg-1">
					<br></br>
					<br></br>
				<img src="https://i.imgur.com/qj5wJo9.png" height=350 width=350 alt="" class="img-fluid"/>
			</div>
		</div>
	</div>
</section>

<section class="about-us py-5">
	<div class="container py-md-3">
		<div class="row bottom-grids">
			<div class="col-lg-7 col-md-1 px-sm-0">
				<h3 class="my-3"> [éš¨ç­†] StackGAN: Text to Photo-realistic Image Synthesis with Stacked Generative Adversarial Networks

				</h3>       
				<p class="mb-4"> æœ¬ç¯‡paperæƒ³è§£æ±ºçš„å•é¡Œï¼Œæ˜¯æƒ³è¦é‡å°çµ¦å®šçš„text descriptionï¼Œç”¢ç”Ÿhigh-quality imagesã€‚ä½œè€…æå‡ºStackGANä¾†ç”¢ç”Ÿ256x256çš„ç…§ç‰‡ã€‚æ•´å€‹è¨ˆç®—éç¨‹åˆ†æˆå…©å€‹éšæ®µï¼Œç¬¬ä¸€å€‹éšæ®µç”¢ç”Ÿç‰©ä»¶çš„primitive shapeå’Œå¤§è‡´çš„colorsï¼Œç¬¬äºŒéšæ®µå‰‡ç”¢ç”Ÿè¼ƒphoto-realistic detailsã€‚å¦å¤–ä½œè€…é‚„æå‡ºconditioning augmentationçš„æŠ€å·§ï¼Œä¾†ç”¢ç”Ÿè¼ƒç‚ºå¹³æ»‘çš„latent conditioning manifoldã€‚

				</p>        
				<a href="https://arxiv.org/abs/1612.03242">Paper</a>             
				<a href="https://hackmd.io/XDLQiXx1Qiuwl-A5-OqPrw">Note</a>              
				<a href="https://github.com/hanzhanggit/StackGAN">Code</a>              
			</div>
			<div class="col-lg7 offset-sm-1 px-lg-1">
					<br></br>
					<br></br>
				<img src="https://i.imgur.com/u4otoHn.png" height=350 width=350 alt="" class="img-fluid"/>
			</div>
		</div>
	</div>
</section>


<section class="about-us py-5">
	<div class="container py-md-3">
		<div class="row bottom-grids">
			<div class="col-lg-7 col-md-1 px-sm-0">
				<h3 class="my-3"> ELEGANT: Exchanging Latent Encodings with GAN for Transferring Multiple Face Attributes

				</h3>       
				<p class="mb-4"> å°æ–¼face attribute transferçš„å•é¡Œï¼Œç›®å‰é‚„æœ‰ä¸‰å€‹çˆ­è­°ï¼š(1) ç›®å‰éƒ½æ˜¯å¾latent spaceç›´æ¥ç”¢ç”Ÿåœ–åƒï¼Œè€Œæ²’è¾¦æ³•å¾examplarsç”¢ç”Ÿåœ–åƒ (2) æ²’è¾¦æ³•åŒæ™‚æ”¹è®Šå¤šå€‹attribute (3) ç”¢ç”Ÿçš„åœ–åƒæœ‰artifactã€‚æœ¬ç¯‡paperæå‡ºäº¤æ›latent encodingçš„æ€æƒ³ï¼Œä¸¦ä»¥æ­¤æå‡ºæ–°çš„æ¶æ§‹ï¼šELEGANT(Exchanging Latent Encoding with GAN for Transferring multiple face attributes)ï¼Œåœ¨é€™æ¨£çš„æ€æƒ³ä¸‹ï¼Œæ‰€æœ‰çš„attributeéƒ½å¯è¢«encodeï¼Œä¸”å…·å‚™disentanglementçš„ç‰¹æ€§ã€‚

				</p>        
				<a href="https://arxiv.org/abs/1803.10562">Paper</a>             
				<a href="https://hackmd.io/B8SFZ_10RBKYFD42HCeFrA">Note</a>              
				<a href="https://github.com/Prinsphield/ELEGANT">Code</a>              
			</div>
			<div class="col-lg7 offset-sm-1 px-lg-1">
					<br></br>
					<br></br>
				<img src="https://i.imgur.com/mBw7i1L.png" height=350 width=350 alt="" class="img-fluid"/>
			</div>
		</div>
	</div>
</section>

<section class="about-us py-5">
	<div class="container py-md-3">
		<div class="row bottom-grids">
			<div class="col-lg-7 col-md-1 px-sm-0">
				<h3 class="my-3"> Attention-aware Multi-stroke Style Transfer

				</h3>       
				<p class="mb-4"> ä»¥å‰style transferçš„æ–¹æ³•æ²’è¾¦æ³•æ•´åˆcontent imageå’Œstylized imageä¸­çš„visual attention spatial distributionï¼Œæˆ–æ˜¯é€éä¸åŒç¨‹åº¦çš„brush strokesä¾†ç¹ªè£½åœ–åƒã€‚æœ¬æ–‡å‰‡æå‡ºä¸€ç¨®attention-aware multi-stroke style transferä¾†åŒæ™‚è§£æ±ºé€™å…©å€‹å•é¡Œï¼Œå°‡attention mapä¸­çš„salient characteristicçµ¦æ•´åˆé€²ä¾†ï¼ŒåŠ å…¥ä¸åŒspatial regionä¸­çš„multiple stroke patternï¼Œä¾†é”åˆ°æ›´å¥½çš„æ¸²æŸ“æ•ˆæœï¼

				</p>        
				<a href="https://arxiv.org/abs/1901.05127">Paper</a>             
				<a href="https://hackmd.io/CnYAlsF2TOCcgvIo3wTDSQ">Note</a>              
				<a href="https://github.com/JianqiangRen/AAMS">Code</a>              
			</div>
			<div class="col-lg7 offset-sm-1 px-lg-1">
					<br></br>
					<br></br>
				<img src="https://i.imgur.com/tgDYpuB.png" height=350 width=350 alt="" class="img-fluid"/>
			</div>
		</div>
	</div>
</section>

<section class="about-us py-5">
	<div class="container py-md-3">
		<div class="row bottom-grids">
			<div class="col-lg-7 col-md-1 px-sm-0">
				<h3 class="my-3"> A Style-Aware Content Loss for Real-time HD Style Transfer

				</h3>       
				<p class="mb-4"> é‡å°é¢¨æ ¼è½‰æ›ï¼Œä»¥å‰çš„å·¥ä½œå¤§å¤šæ˜¯ç”¨pre-trained CNNä¾†æ¯”è¼ƒé¢¨æ ¼å­¸å¾—å¥½ä¸å¥½ï¼Œè­¬å¦‚VGGï¼Œä½†é€™æœƒå—åˆ°ImageNet BBOXçš„biasçš„å½±éŸ¿ï¼Œå› ç‚ºImageNetæœ¬èº«æ˜¯åšè¾¨è­˜çš„ï¼Œä¸æ˜¯åšé¢¨æ ¼è½‰æ›çš„ï¼ŒæŠŠå½±åƒåˆ†æˆå¤šå€‹boxå°è¡¡é‡è—è¡“ä¸¦æ²’æœ‰ç›´æ¥é—œä¿‚ï¼Œæœ¬ç¯‡paperæå‡ºä»¥audo-encoderç‚ºåŸºç¤çš„é¢¨æ ¼è½‰æ›ç¶²è·¯ï¼Œä¸¦çµåˆGANå’Œstyle-aware content lossï¼Œä½¿å¾—ç¶²è·¯å¯ä»¥æ•æ‰åˆ°é¢¨æ ¼å½±éŸ¿å…§å®¹çš„å¾®å¦™æœ¬è³ªï¼Œè­¬å¦‚èªªé˜å¡”ç¨å¾®æœ‰ç‰¹è‰²çš„æ‰­æ›²ï¼Œä¸Šåœ–æœ€å³é‚Šçš„columnã€‚

				</p>        
				<a href="https://arxiv.org/abs/1807.10201">Paper</a>             
				<a href="https://hackmd.io/MmCxsV7HS9OsLvjRjFG2LQ">Note</a>              
				<a href="https://github.com/CompVis/adaptive-style-transfer">Code</a>              
			</div>
			<div class="col-lg7 offset-sm-1 px-lg-1">
					<br></br>
					<br></br>
				<img src="https://i.imgur.com/R7Af10e.png" height=350 width=350 alt="" class="img-fluid"/>
			</div>
		</div>
	</div>
</section>

<section class="about-us py-5">
	<div class="container py-md-3">
		<div class="row bottom-grids">
			<div class="col-lg-7 col-md-1 px-sm-0">
				<h3 class="my-3"> WarpGAN: Automatic Caricature Generation

				</h3>       
				<p class="mb-4"> æœ¬ç¯‡è«–æ–‡æå‡ºWarpGANï¼Œä¾†å°è¼¸å…¥çš„è‡‰éƒ¨å½±åƒç”¢ç”Ÿcaricaturesï¼ˆæ¼«ç•«æ•ˆæœï¼‰ï¼ŒåŒæ™‚ï¼Œç¶²è·¯ä¹Ÿç”¢ç”Ÿä¸€äº›å¯ä¿®æ”¹çš„control pointsï¼Œè®“è‡‰éƒ¨ç…§ç‰‡å¯ä»¥è¢«warpæˆcaricatureï¼Œé™¤äº†å¯å®¢è£½åŒ–å¦‚ä½•ç”¢ç”Ÿface caricatureå¤–ï¼Œé‚„åŒæ™‚ä¿æœ‰identityçš„ç‰¹æ€§ï¼Œå¯¦é©—çµæœèªªæ˜WarpGANå¯ä»¥ç”¢ç”Ÿå¤šæ¨£çš„caricaturesï¼æ•ˆæœå¦‚ä¸Šåœ–æ‰€ç¤ºã€‚

				</p>        
				<a href="https://arxiv.org/abs/1811.10100">Paper</a>             
				<a href="https://hackmd.io/-jfQoBtTTfqRgYPitHgdpw">Note</a>              
				<a href="https://github.com/seasonSH/WarpGAN">Code</a>              
			</div>
			<div class="col-lg7 offset-sm-1 px-lg-1">
					<br></br>
					<br></br>
				<img src="https://i.imgur.com/nkUjMOa.png" height=350 width=350 alt="" class="img-fluid"/>
			</div>
		</div>
	</div>
</section>

<section class="about-us py-5">
	<div class="container py-md-3">
		<div class="row bottom-grids">
			<div class="col-lg-7 col-md-1 px-sm-0">
				<h3 class="my-3"> WarpGAN: Automatic Caricature Generation

				</h3>       
				<p class="mb-4"> æœ¬ç¯‡è«–æ–‡æå‡ºWarpGANï¼Œä¾†å°è¼¸å…¥çš„è‡‰éƒ¨å½±åƒç”¢ç”Ÿcaricaturesï¼ˆæ¼«ç•«æ•ˆæœï¼‰ï¼ŒåŒæ™‚ï¼Œç¶²è·¯ä¹Ÿç”¢ç”Ÿä¸€äº›å¯ä¿®æ”¹çš„control pointsï¼Œè®“è‡‰éƒ¨ç…§ç‰‡å¯ä»¥è¢«warpæˆcaricatureï¼Œé™¤äº†å¯å®¢è£½åŒ–å¦‚ä½•ç”¢ç”Ÿface caricatureå¤–ï¼Œé‚„åŒæ™‚ä¿æœ‰identityçš„ç‰¹æ€§ï¼Œå¯¦é©—çµæœèªªæ˜WarpGANå¯ä»¥ç”¢ç”Ÿå¤šæ¨£çš„caricaturesï¼æ•ˆæœå¦‚ä¸Šåœ–æ‰€ç¤ºã€‚

				</p>        
				<a href="https://arxiv.org/abs/1811.10100">Paper</a>             
				<a href="https://hackmd.io/-jfQoBtTTfqRgYPitHgdpw">Note</a>              
				<a href="https://github.com/seasonSH/WarpGAN">Code</a>              
			</div>
			<div class="col-lg7 offset-sm-1 px-lg-1">
					<br></br>
					<br></br>
				<img src="https://i.imgur.com/nkUjMOa.png" height=350 width=350 alt="" class="img-fluid"/>
			</div>
		</div>
	</div>
</section>

<section class="about-us py-5">
	<div class="container py-md-3">
		<div class="row bottom-grids">
			<div class="col-lg-7 col-md-1 px-sm-0">
				<h3 class="my-3"> Few-Shot Adversarial Learning of Realistic Neural Talking Head Models

				</h3>       
				<p class="mb-4"> æœ¬ç¯‡paperæƒ³è¦è§£æ±ºçš„å•é¡Œæ˜¯neural talking head modelï¼Œç™½è©±ä¾†èªªå°±æ˜¯ç”¢ç”Ÿä¸€å€‹èªªè©±çš„äººé ­videoï¼Œä½†ç‰¹åˆ¥çš„åœ°æ–¹åœ¨æ–¼å¯ä»¥é‡å°few-shotæˆ–one-shotä¾†ä½œå®¢è£½åŒ–ï¼Œé€™æ¨£ä¸€ä¾†æ”¶æ–‚é€Ÿåº¦æœƒå¾ˆå¿«ï¼

				</p>        
				<a href="https://arxiv.org/abs/1905.08233">Paper</a>             
				<a href="https://hackmd.io/sKuG1xW9SUeU6mvzaPhMsA">Note</a>              
				<a href="https://github.com/grey-eye/talking-heads">Code</a>              
			</div>
			<div class="col-lg7 offset-sm-1 px-lg-1">
					<br></br>
					<br></br>
				<img src="https://i.imgur.com/jvk7hty.png" height=350 width=350 alt="" class="img-fluid"/>
			</div>
		</div>
	</div>
</section>

<section class="about-us py-5">
	<div class="container py-md-3">
		<div class="row bottom-grids">
			<div class="col-lg-7 col-md-1 px-sm-0">
				<h3 class="my-3"> Deep Flow-Guided Video Inpainting

				</h3>       
				<p class="mb-4"> æœ¬ç¯‡æƒ³è§£æ±ºçš„æ˜¯domain adaptationçš„å•é¡Œã€‚ä»¥å‰å¤§éƒ¨åˆ†çš„æ–¹æ³•æ˜¯æƒ³è¦å­¸ç¿’domain invariant representationã€‚æœ¬ç¯‡çš„æ€è·¯ä¹Ÿæ˜¯é¡ä¼¼ï¼Œä½†ä½¿ç”¨äº†duplex adversarial discriminator (DupGAN)ã€‚æ•´é«”ç¶²è·¯åŒ…å«äº†ä¸‰å€‹éƒ¨åˆ†ï¼šencoder, generatorå’Œå…©å€‹discriminatorsã€‚Generatoråœ¨ç”Ÿæˆå½±åƒæ™‚æœƒconditon onä¸€å€‹domain codeï¼Œä¾†ç”Ÿæˆä¸åŒdomainçš„å½±åƒã€‚åœ¨é€™æ¨£çš„æ¡†æ¶ä¸‹ï¼Œä¸åƒ…å¯ä»¥å­¸åˆ°domain invariantç‰¹æ€§ï¼Œé‚„å¯ä»¥ä¿ç•™category information

				</p>        
				<a href="https://arxiv.org/abs/1905.02884">Paper</a>             
				<a href="https://hackmd.io/I1iWYy6gTfOzI_VrtsNWfQ">Note</a>              
				<a href="https://github.com/nbei/Deep-Flow-Guided-Video-Inpainting">Code</a>              
			</div>
			<div class="col-lg7 offset-sm-1 px-lg-1">
					<br></br>
					<br></br>
				<img src="https://i.imgur.com/ZXHV8En.png" height=350 width=350 alt="" class="img-fluid"/>
			</div>
		</div>
	</div>
</section>

<section class="about-us py-5">
	<div class="container py-md-3">
		<div class="row bottom-grids">
			<div class="col-lg-7 col-md-1 px-sm-0">
				<h3 class="my-3"> Duplex Generative Adversarial Network for Unsupervised Domain Adaptation Lanqing

				</h3>       
				<p class="mb-4"> æœ¬ç¯‡æƒ³è§£æ±ºçš„æ˜¯domain adaptationçš„å•é¡Œã€‚ä»¥å‰å¤§éƒ¨åˆ†çš„æ–¹æ³•æ˜¯æƒ³è¦å­¸ç¿’domain invariant representationã€‚æœ¬ç¯‡çš„æ€è·¯ä¹Ÿæ˜¯é¡ä¼¼ï¼Œä½†ä½¿ç”¨äº†duplex adversarial discriminator (DupGAN)ã€‚æ•´é«”ç¶²è·¯åŒ…å«äº†ä¸‰å€‹éƒ¨åˆ†ï¼šencoder, generatorå’Œå…©å€‹discriminatorsã€‚Generatoråœ¨ç”Ÿæˆå½±åƒæ™‚æœƒconditon onä¸€å€‹domain codeï¼Œä¾†ç”Ÿæˆä¸åŒdomainçš„å½±åƒã€‚åœ¨é€™æ¨£çš„æ¡†æ¶ä¸‹ï¼Œä¸åƒ…å¯ä»¥å­¸åˆ°domain invariantç‰¹æ€§ï¼Œé‚„å¯ä»¥ä¿ç•™category information

				</p>        
				<a href="http://openaccess.thecvf.com/content_cvpr_2018/html/Hu_Duplex_Generative_Adversarial_CVPR_2018_paper.html">Paper</a>             
				<a href="https://hackmd.io/HUaT8crbRpOtyRvWm4NCIw">Note</a>              
				<a href="http://vipl.ict.ac.cn/view_database.php?id=6">Code</a>              
			</div>
			<div class="col-lg7 offset-sm-1 px-lg-1">
					<br></br>
					<br></br>
				<img src="https://i.imgur.com/PmSlzbe.png" height=350 width=350 alt="" class="img-fluid"/>
			</div>
		</div>
	</div>
</section>

<section class="about-us py-5">
	<div class="container py-md-3">
		<div class="row bottom-grids">
			<div class="col-lg-7 col-md-1 px-sm-0">
				<h3 class="my-3"> MoCoGAN: Decomposing Motion and Content for Video Generation

				</h3>       
				<p class="mb-4"> æœ¬ç¯‡paperæå‡ºMoCoGANä¾†è§£æ±ºvideo generationã€‚åŸºæœ¬æ€è·¯æ˜¯ï¼Œä¸€å¼µå½±åƒå¯ä»¥è¢«æ‹†è§£æˆcontentå’Œmotionçš„çµ„åˆï¼Œcontentä»£è¡¨ç•«é¢ä¸­çš„ç‰©é«”ï¼Œmotionä»£è¡¨ç‰©é«”ç§»å‹•æ€§ã€‚MoCoGANæœƒæŠŠä¸€ç³»åˆ—çš„random vectoræŠ•å°„æˆä¸€ç³»åˆ—çš„åœ–ç‰‡ã€‚ç•¶contentå›ºå®šæ™‚ï¼Œmotionå‰‡å¯çœ‹æˆæ˜¯ä¸€å€‹éš¨æ©Ÿéç¨‹ï¼Œå¯¦é©—è­‰æ˜MoCoGANçš„ç¢ºå¯ä»¥ç”¢ç”Ÿå›ºå®šcontentä¸åŒmotionçš„å½±ç‰‡ï¼ä¸Šåœ–æ˜¯ç¤ºæ„åœ–ã€‚

				</p>        
				<a href="https://arxiv.org/abs/1707.04993">Paper</a>             
				<a href="https://hackmd.io/50-9-rtzTRO4jDNfHX9G7A">Note</a>              
				<a href="https://github.com/sergeytulyakov/mocogan">Code</a>              
			</div>
			<div class="col-lg7 offset-sm-1 px-lg-1">
					<br></br>
					<br></br>
				<img src="https://i.imgur.com/RTPjz2v.png" height=350 width=350 alt="" class="img-fluid"/>
			</div>
		</div>
	</div>
</section>

<section class="about-us py-5">
	<div class="container py-md-3">
		<div class="row bottom-grids">
			<div class="col-lg-7 col-md-1 px-sm-0">
				<h3 class="my-3"> Features for Multi-Target Multi-Camera Tracking and Re-Identification

				</h3>       
				<p class="mb-4"> é€™ç¯‡paperè§£æ±ºäº†å…©å€‹å•é¡Œï¼šMTMCT(multi-target multi-camera tracking)å’ŒPerson Re-ID(re-identification)çš„å•é¡Œï¼Œä½œè€…æå‡ºäº†å‰µæ–°çš„adaptive weighted triplet losså’Œhard-identity miningå…©å€‹æŠ€å·§ï¼Œä¸¦æ¸¬è©¦åœ¨DukeMTMCè³‡æ–™é›†ä¸­ï¼Œå–å¾—äº†æ›´å¥½çš„Re-IDå’ŒMTMCT scoreï¼

				</p>        
				<a href="https://arxiv.org/abs/1803.10859">Paper</a>             
				<a href="https://hackmd.io/7VwFjWRtQxSFKNmO7H-usg">Note</a>              
			</div>
			<div class="col-lg7 offset-sm-1 px-lg-1">
					<br></br>
					<br></br>
				<img src="https://i.imgur.com/sSLinAx.png" height=350 width=350 alt="" class="img-fluid"/>
			</div>
		</div>
	</div>
</section>

<section class="about-us py-5">
	<div class="container py-md-3">
		<div class="row bottom-grids">
			<div class="col-lg-7 col-md-1 px-sm-0">
				<h3 class="my-3"> Scaling and Benchmarking Self-Supervised Visual Representation Learning

				</h3>       
				<p class="mb-4"> åœ¨æœ¬ç¯‡paperä¸­ï¼Œä½œè€…é‡æ–°å¯©è¦–2å€‹æœ‰åçš„self-supervised learningæ–¹æ³•(Jigsawå’ŒColorization)ï¼Œä¸¦æ“´å±•è¨“ç·´å½±åƒè‡³1å„„å¼µç…§ç‰‡ã€‚ä½œè€…æ™‚ååœ¨ä¸åŒçš„taskä¸Šï¼ŒåŒ…åˆ®object detectionã€3D surface normal estimationå’Œvisual navigationï¼Œå¯¦é©—è­‰æ˜æŸäº›ä»»å‹™çš„æ•ˆèƒ½è¶…ésupervised learningï¼ä½†ä½œè€…ä¹Ÿè¡¨æ˜ç›®å‰çš„self-supervised methodä¸¦æ²’è¾¦æ³•å……åˆ†å­¸ç¿’åˆ°è³‡æ–™ä¸­çš„high level semantic representationã€‚

				</p>        
				<a href="https://arxiv.org/abs/1905.01235">Paper</a>             
				<a href="https://hackmd.io/S6AZMMjsQKCBeOmrEe0pDA">Note</a>              
			</div>
			<div class="col-lg7 offset-sm-1 px-lg-1">
					<br></br>
					<br></br>
				<img src="https://i.imgur.com/mYINJqC.png" height=350 width=350 alt="" class="img-fluid"/>
			</div>
		</div>
	</div>
</section>

<section class="about-us py-5">
	<div class="container py-md-3">
		<div class="row bottom-grids">
			<div class="col-lg-7 col-md-1 px-sm-0">
				<h3 class="my-3"> Features for Multi-Target Multi-Camera Tracking and Re-Identification

				</h3>       
				<p class="mb-4"> é€™ç¯‡paperè§£æ±ºäº†å…©å€‹å•é¡Œï¼šMTMCT(multi-target multi-camera tracking)å’ŒPerson Re-ID(re-identification)çš„å•é¡Œï¼Œä½œè€…æå‡ºäº†å‰µæ–°çš„adaptive weighted triplet losså’Œhard-identity miningå…©å€‹æŠ€å·§ï¼Œä¸¦æ¸¬è©¦åœ¨DukeMTMCè³‡æ–™é›†ä¸­ï¼Œå–å¾—äº†æ›´å¥½çš„Re-IDå’ŒMTMCT scoreï¼

				</p>        
				<a href="https://arxiv.org/abs/1803.10859">Paper</a>             
				<a href="https://hackmd.io/7VwFjWRtQxSFKNmO7H-usg">Note</a>              
			</div>
			<div class="col-lg7 offset-sm-1 px-lg-1">
					<br></br>
					<br></br>
				<img src="https://i.imgur.com/sSLinAx.png" height=350 width=350 alt="" class="img-fluid"/>
			</div>
		</div>
	</div>
</section>

<section class="about-us py-5">
	<div class="container py-md-3">
		<div class="row bottom-grids">
			<div class="col-lg-7 col-md-1 px-sm-0">
				<h3 class="my-3"> O-GAN: Extremely Concise Approach for Auto-Encoding Generative Adversarial Networks

				</h3>       
				<p class="mb-4"> æœ¬paperæå‡ºO-GANs(Orthogonal Generative Adversarial Networks)ï¼Œé€éæ–°å¢åŠ ä¸€å€‹é¡å¤–çš„æå¤±é …ï¼Œä½¿å¾—discriminatorè®Šæˆä¸€å€‹å¾ˆå¥½çš„encoderï¼Œä¸”é€™æ¨£çš„è¨­è¨ˆä¹Ÿä¸æœƒé™ä½discriminatorçš„è‡ªç”±åº¦ã€‚æœ¬ç¯‡paperä¹Ÿæ˜¯æœ€ç°¡å–®çš„æ–¹æ³•ï¼Œè®“GANæ“æœ‰auto-encodingçš„èƒ½åŠ›ï¼

				</p>        
				<a href="https://arxiv.org/abs/1903.01931">Paper</a>             
				<a href="https://hackmd.io/wC1G-iMkSf2SkE-rdgw97A">Note</a>              
				<a href="https://github.com/bojone/o-gan">Code</a>
			</div>
			<div class="col-lg7 offset-sm-1 px-lg-1">
					<br></br>
					<br></br>
				<img src="https://i.imgur.com/QgtsYYy.png" height=350 width=350 alt="" class="img-fluid"/>
			</div>
		</div>
	</div>
</section>

<section class="about-us py-5">
	<div class="container py-md-3">
		<div class="row bottom-grids">
			<div class="col-lg-7 col-md-1 px-sm-0">
				<h3 class="my-3"> AutoAugment: Learning Augmentation Strategies from Data

				</h3>       
				<p class="mb-4"> ç›®å‰åšdata argumentationçš„æ–¹æ³•éƒ½æ˜¯è‡ªå·±æ‰‹å‹•è¨­è¨ˆçš„ã€‚æœ¬paperæå‡ºAutoAugmentï¼Œå¯è‡ªå‹•æœç´¢æœ€é©åˆçš„augmentation policiesã€‚ä¸€å€‹augmentation policieså¯èƒ½åŒ…å«è¨±å¤šsub-policiesï¼Œè€Œsub-policyåŒ…å«äº†å…©å€‹operationï¼Œæ¯å€‹operationå¯ä»¥æ˜¯æ—‹è½‰ã€å¹³ç§»ã€æ‰­æ›²ç­‰å‹•ä½œï¼Œåœ¨å¤–åŠ ä¸Šæ©Ÿç‡å’Œå¤§å°ã€‚é€éä½œè€…æå‡ºäº†æœç´¢æ¼”ç®—æ³•ï¼ŒæŒ‘é¸å‡ºèƒ½è®“validation accæœ€é«˜çš„policiesä¾†ç•¶ä½œçµæœï¼ç™½è©±ä¸€é»èªªå°±æ˜¯ï¼šç”¨æœç´¢æ¼”ç®—æ³•ä¾†å–ä»£æ‰‹å‹•æƒ³data augmentationçš„æ–¹å¼ï¼

				</p>        
				<a href="https://arxiv.org/abs/1805.09501">Paper</a>             
				<a href="https://hackmd.io/SZMmecX3QxC0eRDtXyVHfw">Note</a>              
				<a href="https://github.com/DeepVoltaire/AutoAugment">Code</a>
			</div>
			<div class="col-lg7 offset-sm-1 px-lg-1">
					<br></br>
					<br></br>
				<img src="https://i.imgur.com/479Vn4Q.png" height=350 width=350 alt="" class="img-fluid"/>
			</div>
		</div>
	</div>
</section>

<section class="about-us py-5">
	<div class="container py-md-3">
		<div class="row bottom-grids">
			<div class="col-lg-7 col-md-1 px-sm-0">
				<h3 class="my-3"> Billion-scale semi-supervised learning for image classification

				</h3>       
				<p class="mb-4"> æœ¬ç¯‡paperæå‡ºä¸€å€‹semi-supervised learning pipelineï¼Œä¾†è§£æ±ºimage classificationçš„å•é¡Œã€‚å…¶æ¦‚å¿µæ˜¯åŸºæ–¼teacher-student paradigmã€‚é€™æ¨£çš„åšæ³•å¯ä»¥é‡å°target architectureæå‡å¾ˆå¤šperformanceï¼

				</p>        
				<a href="https://arxiv.org/abs/1905.00546">Paper</a>             
				<a href="https://hackmd.io/Ap2WPnvJRgGkRlD2say86A">Note</a>              
			</div>
			<div class="col-lg7 offset-sm-1 px-lg-1">
					<br></br>
					<br></br>
				<img src="https://i.imgur.com/MYSTPPW.png" height=350 width=350 alt="" class="img-fluid"/>
			</div>
		</div>
	</div>
</section>

<section class="about-us py-5">
	<div class="container py-md-3">
		<div class="row bottom-grids">
			<div class="col-lg-7 col-md-1 px-sm-0">
				<h3 class="my-3"> Play as You Like: Timbre-enhanced Multi-modal Music Style Transfer

				</h3>       
				<p class="mb-4"> æœ¬paperä½¿ç”¨äº†MUNITçš„æ¶æ§‹ä¾†åšmusic-to-music transformationã€‚ç‚ºäº†æŠ“åˆä¸åŒæ¨‚å™¨çš„éŸ³è‰²å’Œæ¨‚å™¨ç›¸é—œæ¼”å¥ç´°ç¯€ï¼Œè¼¸å…¥æ··åˆäº†4ç¨®ç‰¹å¾µï¼ŒåŒ…æ‹¬MFCCã€spectral differenceã€spectrogramå’Œspectral envelopï¼Œä¸¦ä½¿ç”¨RaGANã€‚æœ€å¾Œåšåœ¨ä¸‰ç¨®ä¸åŒçš„é¢¨æ ¼æ¨‚å™¨ä¸Šï¼ŒåŒ…æ‹¬piano soloã€guitar soloå’Œstring quartetã€‚

				</p>        
				<a href="https://arxiv.org/pdf/1811.12214.pdf">Paper</a>             
				<a href="https://hackmd.io/M5iRJzrbTsiQiboFXYWX0g">Note</a>              
				<a href="https://github.com/ChienYuLu/Play-As-You-Like-Timbre-Enhanced-Multi-modal-Music-Style-Transfer">Code</a>
			</div>
			<div class="col-lg7 offset-sm-1 px-lg-1">
					<br></br>
					<br></br>
				<img src="https://i.imgur.com/SKgUbwI.png" height=350 width=350 alt="" class="img-fluid"/>
			</div>
		</div>
	</div>
</section>

<section class="about-us py-5">
	<div class="container py-md-3">
		<div class="row bottom-grids">
			<div class="col-lg-7 col-md-1 px-sm-0">
				<h3 class="my-3"> Learning Features of Music from Scratch

				</h3>       
				<p class="mb-4"> æœ¬ç¯‡è«–æ–‡æå‡ºäº†ä¸€å€‹æ–°çš„éŸ³æ¨‚è³‡æ–™é›†ï¼šMusicNetï¼Œè€Œè¨“ç·´çš„æ™‚å€™æ˜¯å®šç¾©ä¸€å€‹multi-label note predictionï¼Œè—‰æ­¤ä¾†è¡¡é‡é€™å€‹è³‡æ–™é›†æ˜¯å¦å¤ è±å¯Œï¼

				</p>        
				<a href="https://arxiv.org/abs/1611.09827">Paper</a>             
				<a href="https://hackmd.io/hlO68bITSUyKdUOuMJr8Fg">Note</a>              
				<a href="https://github.com/jthickstun/pytorch_musicnet">Code</a>
			</div>
			<div class="col-lg7 offset-sm-1 px-lg-1">
					<br></br>
					<br></br>
				<img src="https://i.imgur.com/aLliN3j.png" height=350 width=350 alt="" class="img-fluid"/>
			</div>
		</div>
	</div>
</section>

<section class="about-us py-5">
	<div class="container py-md-3">
		<div class="row bottom-grids">
			<div class="col-lg-7 col-md-1 px-sm-0">
				<h3 class="my-3"> Music Thumbnailing via Neural Attention Modeling of Music Emotion

				</h3>       
				<p class="mb-4"> music thumbnailingçš„ç›®æ¨™æ˜¯å¸Œæœ›æ‰¾åˆ°ä¸€å€‹è¼ƒçŸ­ä¸”é€£çºŒçš„éŸ³æ¨‚ç‰‡æ®µï¼Œä½¿å¾—é€™å€‹ç‰‡æ®µæœ€èƒ½ä»£è¡¨ä¸€é¦–æ­Œã€‚æ¦‚å¿µæ˜¯çµåˆemotion recognitionä¾†è§£æ±ºmusic chorus selectionçš„å•é¡Œã€‚ä½œè€…å¼•å…¥LSTMå’Œattention layeråˆ°CNNä¸­ï¼Œä¾†åšmusic emotion classificationï¼›attention layerå‰‡æœƒå°æ¯å€‹3ç§’é˜çš„chunkè©•ä¼°ä»–çš„é‡è¦æ€§ï¼Œç”¨31000é¦–æ­Œå’Œç›¸å°æ‡‰çš„emotion labelsä¾†è¨“ç·´ã€‚å¯¦é©—çµæœè¡¨æ˜æœ‰80%çš„æ­Œæ›²æœƒæŠŠå‰¯æ­Œç•¶ä½œæ˜¯thumbnailsã€‚

				</p>        
				<a href="http://mac.citi.sinica.edu.tw/~yang/pub/huang17apsipa.pdf">Paper</a>             
				<a href="https://hackmd.io/WHdadI_pQIiWHkBB9oFuaA">Note</a>              
			</div>
			<div class="col-lg7 offset-sm-1 px-lg-1">
					<br></br>
					<br></br>
				<img src="https://i.imgur.com/Jr2wWRv.png" height=350 width=350 alt="" class="img-fluid"/>
			</div>
		</div>
	</div>
</section>

<section class="about-us py-5">
	<div class="container py-md-3">
		<div class="row bottom-grids">
			<div class="col-lg-7 col-md-1 px-sm-0">
				<h3 class="my-3"> Event Localization in Music Auto-tagging

				</h3>       
				<p class="mb-4"> æœ¬ç¯‡æƒ³è§£æ±ºçš„æ˜¯frame-levelçš„music auto-taggingï¼Œå³çµ¦å®šä¸€å€‹music clipï¼Œæˆ‘å€‘æƒ³çŸ¥é“ä»–çš„attributeï¼ŒåŒ…åˆ®æ¨‚å™¨ç¨®é¡ã€é¢¨æ ¼å’Œå…¶ä»–è²å­¸å±¬æ€§ã€‚

				</p>        
				<a href="http://mac.citi.sinica.edu.tw/~yang/pub/liu16mm.pdf">Paper</a>             
				<a href="https://hackmd.io/yTTD0RxaQgWvuHELbLj_Wg">Note</a>           
				<a href="https://github.com/ciaua/clip2frame">Code</a>     
			</div>
			<div class="col-lg7 offset-sm-1 px-lg-1">
					<br></br>
					<br></br>
				<img src="https://i.imgur.com/ScJ5UtV.png" height=350 width=350 alt="" class="img-fluid"/>
			</div>
		</div>
	</div>
</section>

<section class="about-us py-5">
	<div class="container py-md-3">
		<div class="row bottom-grids">
			<div class="col-lg-7 col-md-1 px-sm-0">
				<h3 class="my-3"> Hit Song Prediction for Pop Music by Siamese CNN with Ranking Loss

				</h3>       
				<p class="mb-4"> é€™ç¯‡paperæƒ³è¦è§£çš„å•é¡Œæ˜¯hit song predictionã€‚å°±æ˜¯åœ¨ä¸€é¦–æ­Œè¢«ç™¼è¡Œä»¥å‰ï¼Œé æ¸¬ä»–æ˜¯å¦æœƒå¾ˆç´…ã€‚å‚³çµ±æ–¹æ³•æ˜¯æŠŠä»–çœ‹æˆclassification(ç´…æˆ–ä¸ç´…ï¼‰æˆ–regressionï¼ˆç´…çš„åˆ†æ•¸ï¼‰çš„å•é¡Œï¼Œé€™ç¯‡å‰‡çœ‹æˆæ˜¯rankingçš„å•é¡Œã€‚ä½œè€…ä½¿ç”¨äº†multi-objective siamese CNNï¼Œä¸¦çµåˆäº†Euclidean losså’Œpairwise ranking lossï¼Œä¾†å­¸ç¿’ä¸åŒæ­Œæ›²ä¹‹é–“çš„æ’åé—œä¿‚ã€‚æ ¹æ“šå¯¦é©—é¡¯ç¤ºï¼Œæ­é…ä¸ŠA/B samplingå¯ä»¥æ¯”å…¶ä»–baselineç²å¾—æ›´é«˜çš„æº–ç¢ºåº¦ï¼

				</p>        
				<a href="https://arxiv.org/abs/1710.10814">Paper</a>             
				<a href="https://hackmd.io/g4eKoSD6QSWalLP2FDBx9A">Note</a>           
				<a href="https://github.com/OckhamsRazor/HSP_CNN">Code</a>     
			</div>
			<div class="col-lg7 offset-sm-1 px-lg-1">
					<br></br>
					<br></br>
				<img src="https://i.imgur.com/KzX9T24.png" height=350 width=350 alt="" class="img-fluid"/>
			</div>
		</div>
	</div>
</section>

<section class="about-us py-5">
	<div class="container py-md-3">
		<div class="row bottom-grids">
			<div class="col-lg-7 col-md-1 px-sm-0">
				<h3 class="my-3"> Transferring GANs: generating images from limited data

				</h3>       
				<p class="mb-4"> æœ¬paperæ¢è¨çš„å•é¡Œæ˜¯ï¼ŒæŠŠdomain adaptationçš„æŠ€å·§ç”¨åœ¨GANçš„image generationã€‚çµæœé¡¯ç¤ºåˆ©ç”¨pre-trained networkçš„knowledgeå¯ä»¥ç¸®çŸ­è¨“ç·´æ™‚é–“ï¼Œè€Œä¸”å¦‚æœtarget dataå¾ˆå°‘çš„æƒ…æ³ä¸‹ï¼Œç”¢ç”Ÿçš„åœ–åƒå“è³ªä¹Ÿå¯å¤§å¹…åº¦æå‡ï¼

				</p>        
				<a href="https://arxiv.org/pdf/1805.01677">Paper</a>             
				<a href="https://hackmd.io/DyNQf_RkSLCQ6XH9__HB0Q?view">Note</a>           
				<a href="https://github.com/yaxingwang/Transferring-GANs">Code</a>     
			</div>
			<div class="col-lg7 offset-sm-1 px-lg-1">
					<br></br>
					<br></br>
				<img src="https://i.imgur.com/1Kaj9Dv.png" height=350 width=350 alt="" class="img-fluid"/>
			</div>
		</div>
	</div>
</section>

<section class="about-us py-5">
	<div class="container py-md-3">
		<div class="row bottom-grids">
			<div class="col-lg-7 col-md-1 px-sm-0">
				<h3 class="my-3"> Unsupervised Image Super-Resolution using Cycle-in-Cycle Generative Adversarial Networks

				</h3>       
				<p class="mb-4"> æœ¬ç¯‡paperå°æ–¼super resolutionæœ‰è‘—ä¸åŒçš„çœ‹æ³•ï¼šlow/high resolutionçš„å½±åƒé…å°å…¶å¯¦æ˜¯ç„¡æ³•ç²å¾—çš„ï¼åœ¨å‚³çµ±çš„æ–¹æ³•ä¸­ï¼Œä½è§£æåº¦å½±åƒå…¶å¯¦å·²ç¶“é€€åŒ–ï¼Œåƒé›œä¸€äº›noiseå’Œblurringã€‚æœ¬æ–‡æå‡ºCycle-in-cycleçš„æ¶æ§‹ä¾†è§£æ±ºunpair super resolutionçš„å•é¡Œï¼æ•´å€‹è¨ˆç®—éç¨‹åˆ†æˆå…©æ­¥ã€‚ç¬¬ä¸€ï¼Œæœƒå…ˆå°‡noisyä¸”blurryçš„åœ–ç‰‡æŠ•å°„åˆ°noise-free low-resolutionç©ºé–“ä¸­ï¼Œç¬¬äºŒï¼ŒæœƒæŠŠé€™å€‹intermediate imageé€épre-trained deep modelæŠ•å°„åˆ°high-resolutionç©ºé–“ã€‚

				</p>        
				<a href="https://arxiv.org/abs/1809.00437">Paper</a>             
				<a href="https://hackmd.io/0Oh7ymreT4mh9rlUqEfZCw">Note</a>           
				<a href="https://github.com/Junshk/CinCGAN-pytorch">Code (unofficial)</a>     
			</div>
			<div class="col-lg7 offset-sm-1 px-lg-1">
					<br></br>
					<br></br>
				<img src="https://i.imgur.com/L0AoXFk.png" height=350 width=350 alt="" class="img-fluid"/>
			</div>
		</div>
	</div>
</section>

<section class="about-us py-5">
	<div class="container py-md-3">
		<div class="row bottom-grids">
			<div class="col-lg-7 col-md-1 px-sm-0">
				<h3 class="my-3"> MSG-GAN: Multi-Scale Gradient GAN for Stable Image Synthesis

				</h3>       
				<p class="mb-4"> GANæƒ¡åæ˜­å½°é›£ç”¨çš„å…¶ä¸­ä¸€å€‹åŸå› ï¼Œæ˜¯å› ç‚ºè¨“ç·´éç¨‹ä¸¦ä¸ç©©å®šã€‚å› ç‚ºå¾discriminatorå‚³ééä¾†çš„gradientï¼Œåˆ°generatorå·²ç¶“å¹¾ä¹ä¸å…·æœ‰è³‡è¨Šï¼›æœ¬paperæå‡ºMulti-scale gradient GAN (MSG-GAN)ä¾†è§£æ±ºé€™å€‹å•é¡Œï¼Œå…è¨±discriminatorä¸­ä¸åŒæµå‘ã€ä¸åŒå°ºåº¦çš„gradientç›´æ¥å‚³åˆ°generatorä¸­ï¼Œä½œè€…å¯¦é©—åœ¨CIFAR10ã€Oxford102 flowerså’ŒCelebA-HQä¸­çš†å–å¾—ä¸éŒ¯çš„æ•ˆæœï¼

				</p>        
				<a href="https://arxiv.org/abs/1903.06048">Paper</a>             
				<a href="https://hackmd.io/6GaiqNanSYi0Kx16MVNwiQ?view">Note</a>           
				<a href="https://github.com/akanimax/BMSG-GAN">Code</a>     
			</div>
			<div class="col-lg7 offset-sm-1 px-lg-1">
					<br></br>
					<br></br>
				<img src="https://i.imgur.com/g2LvsxV.png" height=350 width=350 alt="" class="img-fluid"/>
			</div>
		</div>
	</div>
</section>

<section class="about-us py-5">
	<div class="container py-md-3">
		<div class="row bottom-grids">
			<div class="col-lg-7 col-md-1 px-sm-0">
				<h3 class="my-3"> Maximum Classifier Discrepancy for Unsupervised Domain Adaptation

				</h3>       
				<p class="mb-4"> æœ¬ç¯‡paperæå‡ºä¸€å€‹unsupervised domain adaptationçš„æ–¹æ³•ã€‚å‚³çµ±ä¸Šåœ¨è§£é€™å€‹å•é¡Œæ™‚ï¼Œé€šå¸¸ä½¿ç”¨ä¸€å€‹domain classifierï¼Œä¸¦è©¦åœ–è®“source featureå’Œtarget featureè¶Šè¿‘è¶Šå¥½ï¼Œä½†é€™æœ‰å…©å€‹ç¼ºé»ï¼šç¬¬ä¸€ï¼Œé€™é¡çš„æ–¹æ³•ä¸¦æ²’æœ‰ä½¿ç”¨task-specific decision boundaryçš„è³‡è¨Šï¼›ç¬¬äºŒï¼Œä¸åŒdomainæœ‰è‘—ä¸åŒçš„domain-specific characteristicï¼Œä¸€æ˜§åœ°è¦è®“å…©å€‹distributionäº’ç›¸é è¿‘æ˜¯å¾ˆå›°é›£çš„ï¼å› æ­¤æœ¬æ–‡æå‡ºäº†ä¸€å€‹æ–°çš„æ–¹æ³•ï¼Œè©¦åœ–åˆ©ç”¨ä¸¦æœ€å¤§åŒ–task-specific decision boundaryï¼Œæœ€å¤§åŒ–å…©å€‹classifier çš„outputä¾†é”æˆç›®æ¨™ï¼

				</p>        
				<a href="https://arxiv.org/abs/1712.02560">Paper</a>             
				<a href="https://hackmd.io/3MmvzkBcQdyJr2rozCDN-Q?view">Note</a>           
				<a href="https://github.com/mil-tokyo/MCD_DA">Code</a>     
			</div>
			<div class="col-lg7 offset-sm-1 px-lg-1">
					<br></br>
					<br></br>
				<img src="https://raw.githubusercontent.com/mil-tokyo/MCD_DA/master/docs/overview.png" height=350 width=350 alt="" class="img-fluid"/>
			</div>
		</div>
	</div>
</section>

<section class="about-us py-5">
	<div class="container py-md-3">
		<div class="row bottom-grids">
			<div class="col-lg-7 col-md-1 px-sm-0">
				<h3 class="my-3"> Self-Supervised Feature Learning for Semantic Segmentation of Overhead Imagery

				</h3>       
				<p class="mb-4"> é€™ç¯‡paperæƒ³è™•ç†çš„å°è±¡æ˜¯èˆªç©ºå½±åƒ(overhead image)ï¼Œç„¶è€Œé‡å°é€™æ¨£çš„å½±åƒåšsemantic segmentationæ˜¯å€‹å·¨å¤§çš„æŒ‘æˆ°ï¼Œå› ç‚ºæ ¹æœ¬æ²’æœ‰GTï¼Œè€Œä¸”å’Œåœ°é¢ç…§æœ‰è‘—å¾ˆå¤§çš„domain gapã€‚ä½œè€…æå‡ºä¸€ç¨®self-supervisedçš„æ–¹æ³•ä¾†å°overhead imageryåšsemantic segmentationï¼Œä¸¦é€éadversarial trainingæœ‰äº†æ›´å¥½çš„pre-trained featureã€‚

				</p>        
				<a href="http://bmvc2018.org/contents/papers/0345.pdf">Paper</a>             
				<a href="https://hackmd.io/WIGVOhcyQmmzZoVjzygVLQ">Note</a>           
				<a href="https://github.com/suriyasingh/Self-supervision-for-segmenting-overhead-imagery">Code</a>     
			</div>
			<div class="col-lg7 offset-sm-1 px-lg-1">
					<br></br>
					<br></br>
				<img src="https://i.imgur.com/fm6f4is.png" height=350 width=350 alt="" class="img-fluid"/>
			</div>
		</div>
	</div>
</section>

<section class="about-us py-5">
	<div class="container py-md-3">
		<div class="row bottom-grids">
			<div class="col-lg-7 col-md-1 px-sm-0">
				<h3 class="my-3"> Semantic Image Synthesis with Spatially-Adaptive Normalization

				</h3>       
				<p class="mb-4"> æœ¬ç¯‡æå‡ºäº†spatially-adaptive normalizationï¼Œé€²è€Œçµåˆé€²pix2pixHDï¼Œå½¢æˆä¸€å€‹æ–°çš„æ¨¡å‹ç‚ºGauGANï¼Œç”¨ä¾†è§£æ±ºimage synthesizeçš„å•é¡Œã€‚å‚³çµ±çš„CNNå¤§å¤šä½¿ç”¨ç–Šèµ·ä¾†çš„(conv, BN, ReLU)é‹ç®—çµ„åˆï¼Œä½†é€™æ¨£çš„åšæ³•æœƒæŠŠè¼¸å…¥çš„semantic information"æ´—æ‰"ï¼Œå› æ­¤ä½œè€…æå‡ºspatially-adaptiveç‰ˆæœ¬çš„å¯å­¸ç¿’è½‰æ›ï¼Œä¾†è§£æ±ºé€™å€‹çˆ­è­°ã€‚ä¸Šåœ–æ˜¯ä¸€å€‹ç°¡å–®çš„çµæœï¼Œå¦‚æœå…ˆæ±‚å‡ºæœ€å·¦é‚Šcolumnçš„latent representationï¼Œå†é€éSPADEç”Ÿæˆåœ–ç‰‡çš„è©±ï¼Œstyleå°±æœƒæœ‰æ‰€ä¸åŒã€‚

				</p>        
				<a href="https://arxiv.org/abs/1903.07291">Paper</a>             
				<a href="https://hackmd.io/r-u6WR8fRO6uPK7HSC3nZQ">Note</a>           
				<a href="">Code (TBC)</a>     
			</div>
			<div class="col-lg7 offset-sm-1 px-lg-1">
					<br></br>
					<br></br>
				<img src="https://i.imgur.com/N2zZNei.jpg" height=350 width=350 alt="" class="img-fluid"/>
			</div>
		</div>
	</div>
</section>

<section class="about-us py-5">
	<div class="container py-md-3">
		<div class="row bottom-grids">
			<div class="col-lg-7 col-md-1 px-sm-0">
				<h3 class="my-3"> GANimation: Anatomically-aware Facial Animation from a Single Image

				</h3>       
				<p class="mb-4"> å…ˆå‰å·²æœ‰ç ”ç©¶ä¾†åšè‡‰éƒ¨è¡¨æƒ…åˆæˆ(facial expression synthesis)ï¼Œæœ€çŸ¥åçš„ä¾‹å­ä¾¿æ˜¯StarGANï¼Œä½†åƒ…èƒ½å­¸å‡ºé›¢æ•£å‹åˆ¥çš„è¡¨æƒ…(å› ç‚ºåœ¨StarGANä¸­attributeæ˜¯é›¢æ•£è®Šé‡)ã€‚æœ¬ç¯‡paperæå‡ºåŸºæ–¼Action Units(AU)çš„è‡‰éƒ¨è¡¨æƒ…åˆæˆæ–¹æ³•ï¼ŒAUå®šç¾©äº†äººè‡‰è¡¨æƒ…ï¼Œä¸”æ˜¯åˆ†å¸ƒåœ¨ä¸€å€‹ä½å¾®åº¦ä¸”é€£çºŒçš„manifoldä¸­ï¼Œä½œè€…æŒ‡å‡ºåƒ…éœ€ä½¿ç”¨æœ‰AUæ¨™è¨»çš„å½±åƒé€²è¡Œéç›£ç£å¼è¨“ç·´ï¼Œå³å¯é”åˆ°æ›´å¥½çš„æ•ˆæœï¼Œå¯æ¸²æŸ“å‡ºæ›´å¤šæ¨£çš„è¡¨æƒ…ï¼ŒåŒ…æ‹¬è‡‰éƒ¨è‚Œè‚‰çš„å½ˆæ€§åº¦ã€‚

				</p>        
				<a href="https://arxiv.org/pdf/1807.09251.pdf">Paper</a>             
				<a href="https://hackmd.io/uzvBHQ6HRyWcjJLI345a5g">Note</a>           
				<a href="https://github.com/albertpumarola/GANimation">Code</a>     
			</div>
			<div class="col-lg7 offset-sm-1 px-lg-1">
					<br></br>
					<br></br>
				<img src="https://i.imgur.com/3mEf8z8.png" height=350 width=350 alt="" class="img-fluid"/>
			</div>
		</div>
	</div>
</section>

<section class="about-us py-5">
	<div class="container py-md-3">
		<div class="row bottom-grids">
			<div class="col-lg-7 col-md-1 px-sm-0">
				<h3 class="my-3"> Identifying Analogies Across Domains

				</h3>       
				<p class="mb-4"> é›–ç„¶ç¾åœ¨unsupervised identifying analogyçš„ç ”ç©¶å·²ç¶“å¯ä»¥é”åˆ°ä¸éŒ¯çš„æ•ˆæœï¼Œä½†è½‰æ›åœ–åƒçš„visual fidelityä¸¦ä¸è¶³å¤ è­˜åˆ¥åœ¨å¦å¤–ä¸€å€‹domainä¸­çš„matching sampleã€‚æœ¬ç¯‡paperæå‡ºAN-GANï¼Œæ¡ç”¨ä¸€ç¨®åç‚ºmatching-by-synthesisçš„æ€æƒ³ï¼ŒæŠŠè½‰æ›çš„éç¨‹åˆ†æˆå…©éƒ¨ï¼šdomain alignmentå’Œlearning the mapping functionã€‚

				</p>        
				<a href="https://openreview.net/pdf?id=BkN_r2lR-">Paper</a>             
				<a href="https://hackmd.io/Ao5qK-nURTK6vx-lNT1UTw">Note</a>               
			</div>
			<div class="col-lg7 offset-sm-1 px-lg-1">
					<br></br>
					<br></br>
				<img src="https://i.imgur.com/EtlwxhI.png" height=350 width=350 alt="" class="img-fluid"/>
			</div>
		</div>
	</div>
</section>


<section class="about-us py-5">
	<div class="container py-md-3">
		<div class="row bottom-grids">
			<div class="col-lg-7 col-md-1 px-sm-0">
				<h3 class="my-3"> A Closer Look at Few-shot Classification
				</h3>       
				<p class="mb-4"> ç”±æ–¼ä¸åŒçš„few-shot algorithmæœ‰ä¸åŒçš„implementation detailï¼Œä¸”æ¯”è¼ƒçš„æ–¹å¼ä¹Ÿä¸å¤ªä¸€æ¨£ï¼Œå› æ­¤å¾ˆé›£å…¬å¹³çš„æ¯”è¼ƒå“ªä¸€å€‹æ–¹æ³•æ¯”è¼ƒå¥½ã€‚æœ¬ç¯‡paperæå‡ºï¼šç¬¬ä¸€ï¼Œå…¬å¹³çš„åˆ†æèˆ‡æ¯”è¼ƒå¾—çŸ¥ï¼Œå¦‚æœç”¨çš„backbone networkè¼ƒæ·±ï¼Œä¸”domain differenceè¼ƒå°‘çš„è©±ï¼Œä¸åŒçš„æ–¹æ³•éƒ½å¯é¡¯è‘—çš„é™ä½classification gapï¼›ç¬¬äºŒï¼Œç¨å¾®å°ç¶²è·¯åšä¸€äº›æ”¹è‰¯ï¼Œä¾¿å¯åœ¨mini-ImageNetå’ŒCUBå…©å€‹è³‡æ–™é›†æ›´åŠ æå‡SOTAï¼›æœ€å¾Œï¼Œå°æ–¼cross-domainçš„few shot classificationå•é¡Œï¼Œæå‡ºä¸€å€‹æ–°çš„å¯¦é©—è¨­å®šã€‚

				</p>        
				<a href="https://openreview.net/pdf?id=HkxLXnAcFQ">Paper</a>             
				<a href="https://hackmd.io/jmipjbf0TseG_lxd8baWQA?view">Note</a>           
				<a href="https://github.com/wyharveychen/CloserLookFewShot">Code</a>     
			</div>
			<div class="col-lg7 offset-sm-1 px-lg-1">
					<br></br>
					<br></br>
				<img src="https://i.imgur.com/39AVmGL.png" height=350 width=350 alt="" class="img-fluid"/>
			</div>
		</div>
	</div>
</section>

<section class="about-us py-5">
	<div class="container py-md-3">
		<div class="row bottom-grids">
			<div class="col-lg-7 col-md-1 px-sm-0">
				<h3 class="my-3"> DeepFool: a simple and accurate method to fool deep neural networks
				</h3>       
				<p class="mb-4"> å°æ–¼ä»¥å‰adversarial attackçš„æ–¹æ³•ï¼Œä¸¦æ²’æœ‰ä¸€å€‹å¾ˆç²¾æº–çš„æ–¹æ³•å¯ä»¥è¨ˆç®—å¾ˆå°çš„perturbationsã€‚æœ¬ç¯‡paperæå‡ºDeepFoolï¼Œå¯ä»¥è¼ƒæœ‰æ•ˆç‡ä¸¦ç²¾æº–çš„è¨ˆç®—æœ€å°çš„perturbationï¼Œä»¥æ¬ºé¨™classifierã€‚

				</p>        
				<a href="https://arxiv.org/pdf/1511.04599.pdf">Paper</a>             
				<a href="https://hackmd.io/jwfnZWTkQ86R4UNfTwfk2w?view">Note</a>           
				<a href="https://github.com/LTS4/DeepFool/tree/master/Python">Code</a>     
			</div>
			<div class="col-lg7 offset-sm-1 px-lg-1">
					<br></br>
					<br></br>
				<img src="https://i.imgur.com/Rz5rdgh.png" height=350 width=350 alt="" class="img-fluid"/>
			</div>
		</div>
	</div>
</section>

<section class="about-us py-5">
	<div class="container py-md-3">
		<div class="row bottom-grids">
			<div class="col-lg-7 col-md-1 px-sm-0">
				<h3 class="my-3"> Image Super-Resolution as a Defense Against Adversarial Attacks
				</h3>       
				<p class="mb-4"> CNNå°æ–¼å«æœ‰adversarial noise patternçš„è¼¸å…¥å¯èƒ½è¼ƒå®¹æ˜“è¢«æ··æ·†ï¼Œæœ¬paperæå‡ºä¸€ç¨®é˜²ç¦¦æ©Ÿåˆ¶ä¾†ç·©è§£adversarial pertubationé€ æˆçš„æ€§èƒ½ä¸Ÿå¤±å•é¡Œã€‚åœ¨æœ¬ç ”ç©¶ä¸­ï¼Œimage restoration networkæœƒæŠŠoff-the-manifold adversarial sampleæ‹‰å›natural image manifoldä¸­ï¼Œä¸”æ­¤æ–¹æ³•ä¸éœ€è¦ä¿®æ”¹classifierçš„åƒæ•¸ï¼Œä¹Ÿä¸éœ€è¦é¡å¤–çš„éç¨‹å»åµæ¸¬å“ªäº›åœ–ç‰‡æ˜¯adversarial exampleã€‚

				</p>        
				<a href="https://arxiv.org/abs/1901.01677">Paper</a>             
				<a href="https://hackmd.io/zfJ_8XSSQ8iIrEJX3nAjXw">Note</a>           
				<a href="https://github.com/aamir-mustafa/super-resolution-adversarial-defense">Code</a>     
			</div>
			<div class="col-lg7 offset-sm-1 px-lg-1">
					<br></br>
					<br></br>
				<img src="https://i.imgur.com/SY7nZka.png" height=350 width=350 alt="" class="img-fluid"/>
			</div>
		</div>
	</div>
</section>

<section class="about-us py-5">
	<div class="container py-md-3">
		<div class="row bottom-grids">
			<div class="col-lg-7 col-md-1 px-sm-0">
				<h3 class="my-3"> EdgeConnect: Generative Image Inpainting with Adversarial Edge Learning
				</h3>       
				<p class="mb-4"> å…ˆå‰åšimage inpaintingçš„ç ”ç©¶ï¼Œåšå‡ºä¾†çš„çµæœæ™®éå¾ˆå¹³æ»‘æˆ–æ˜¯æ¨¡ç³Šã€‚æœ¬è«–æ–‡æå‡ºEngeConnectï¼Œæ˜¯ä¸€ç¨®å…©éšæ®µçš„å°æŠ—æ˜¯æ¨¡å‹ï¼Œç”±edge generatorå’Œimage completion networkçµ„æˆï¼Œç¶²è·¯æœƒæŠŠå¹»æƒ³å‡ºä¾†çš„edgeç•¶ä½œpriorä¾†æ¸²æŸ“ï¼Œå¯¦é©—åœ¨CelebAå’ŒPlaces2è³‡æ–™é›†ä¸­å–å¾—äº†SOTAã€‚

				</p>        
				<a href="https://arxiv.org/abs/1901.00212">Paper</a>             
				<a href="https://hackmd.io/9npdnYG2QzGJtthZIFPKiA?view">Note</a>           
				<a href="https://github.com/knazeri/edge-connect">Code</a>     
			</div>
			<div class="col-lg7 offset-sm-1 px-lg-1">
					<br></br>
					<br></br>
				<img src="https://i.imgur.com/BsQm5c3.png" height=350 width=350 alt="" class="img-fluid"/>
			</div>
		</div>
	</div>
</section>

<section class="about-us py-5">
	<div class="container py-md-3">
		<div class="row bottom-grids">
			<div class="col-lg-7 col-md-1 px-sm-0">
				<h3 class="my-3"> CCNet: Criss-Cross Attention for Semantic Segmentation
                </h3>       
				<p class="mb-4">  long-range dependencyåœ¨visual understandingè£¡ä¹ŸåŒæ¨£é‡è¦ï¼Œä½†å‚³çµ±CNNçš„respected fieldæ˜¯æœ‰é™çš„ï¼Œå› æ­¤æœ¬æ–‡æå‡ºCriss-Cross Network (CCNet)ã€‚ç¶²è·¯ä¸­å«æœ‰criss-cross attention moduleï¼Œè©²moduleæ”¶é›†äº†å°æ¯å€‹pixelåå­—æ¶è·¯å¾‘ä¸Šçš„contextual informationã€‚æ¯”èµ·Heçš„non-local networkï¼ŒCCNetä¸åƒ…å¯¦ä½œä¸Šè¼ƒç‚ºGPU-friendlyï¼ˆå¿«äº†11å€ï¼‰ï¼Œè¨ˆç®—ä¸Šä¹Ÿè¼ƒæœ‰æ•ˆç‡ï¼ˆFLOPsç‚º15%ï¼‰ </p>        
				<a href="https://arxiv.org/abs/1811.11721">Paper</a>             
				<a href="https://hackmd.io/QDIdfKtFS7-5864v6Xm2kA">Note</a>           
				<a href="https://github.com/speedinghzl/CCNet">Code</a>     
			</div>
			<div class="col-lg7 offset-sm-1 px-lg-1">
					<br></br>
					<br></br>
				<img src="https://i.imgur.com/4sNp6i4.png" height=350 width=350 alt="" class="img-fluid"/>
			</div>
		</div>
	</div>
</section> 

<section class="about-us py-5">
	<div class="container py-md-3">
		<div class="row bottom-grids">
			<div class="col-lg-7 col-md-1 px-sm-0">
				<h3 class="my-3"> Adversarial Discriminative Domain Adaptation
                </h3>       
				<p class="mb-4">  å°æŠ—å¼å­¸ç¿’å¯ä»¥è¢«æ‹¿ä¾†æ”¹å–„recognition taskçš„performanceï¼Œæ¶ˆé™¤domain shiftæˆ–dataset biasé€ æˆçš„æ€§èƒ½æå¤±ã€‚å…ˆå‰çš„ç ”ç©¶å¯åˆ†ç‚ºå…©è€…è¨è«–ï¼š

                    Prior generative approachï¼šè®“generatorçš„éƒ¨ä»½è³‡æ–™åˆ†ä½ˆå„˜é‡ä¸€è‡´ï¼Œä½†é€™é¡å‹çš„æ–¹æ³•æ²’è¾¦æ³•è¢«ç”¨åœ¨domain shiftå¾ˆå¤§çš„æƒ…æ³
                    Prior discriminative approach: è®“discriminatorå„˜é‡ä¿æŒä¸€è‡´ï¼Œé€™é¡å‹çš„æ–¹æ³•å¤§å¤šæ˜¯å¼·è¿«tie weight(share weight)ï¼Œä¹Ÿæ²’æœ‰ç”¨åˆ°GAN çš„æ¦‚å¿µ
                    æœ¬ç ”ç©¶çµåˆäº†discriminative model, weight sharingå’ŒGAN lossçš„æƒ³æ³•ï¼Œæå‡ºäº†Adversarial Discriminative Domain Adaptationæ¡†æ¶(ADDA)ï¼Œæ˜¯ä¸€ç¨®éç›£ç£å¼çš„domain adaptationæ–¹æ³•ã€‚ </p>        
				<a href="https://arxiv.org/abs/1702.05464">Paper </a>             
				<a href="https://hackmd.io/3Fa2I-coRQqBMH42XDo0QA">Note</a>           
				<a href="https://github.com/erictzeng/adda">Code</a>     
			</div>
			<div class="col-lg7 offset-sm-1 px-lg-1">
					<br></br>
					<br></br>
				<img src="https://i.imgur.com/yLsW4Nx.png" height=350 width=350 alt="" class="img-fluid"/>
			</div>
		</div>
    </div>
    
<section class="about-us py-5">
	<div class="container py-md-3">
		<div class="row bottom-grids">
			<div class="col-lg-7 col-md-1 px-sm-0">
				<h3 class="my-3"> InstaGAN: Instance-aware Image-to-Image Translation
                </h3>       
				<p class="mb-4"> åœ¨image-to-image translationçš„ä»»å‹™ä¸­ï¼Œå…ˆå‰çš„æ–¹æ³•æœƒåœ¨è¼ƒç‚ºè¤‡é›œçš„è€ƒé©—ä¸­å¤±æ•—ï¼Œç‰©é«”çš„å½¢ç‹€å¾ˆé›£è¢«ä¿ç•™ï¼Œä¾‹å¦‚æœ‰å¤šå€‹instanceè¦è½‰æ›çš„å ´æ™¯ã€‚æœ¬ç ”ç©¶åˆ©ç”¨instance informationï¼Œæå‡ºäº†instance-aware GAN (InstaGAN)ï¼Œä¸¦å¼•å…¥äº†context preserving lossï¼Œè¿«ä½¿ç¶²è·¯åœ¨target instanceä»¥å¤–çš„ç¯„åœå­¸ç¿’å°ç­‰æ˜ å°„(è¼¸å…¥=è¼¸å‡º)

                </p>        
				<a href="https://arxiv.org/abs/1812.10889">Paper </a>             
				<a href="https://hackmd.io/QYDwy8mBTweaZY2DSdeYaQ">Note</a>           
				<a href="https://github.com/sangwoomo/instagan">Code</a>     
			</div>
			<div class="col-lg7 offset-sm-1 px-lg-1">
					<br></br>
					<br></br>
				<img src="https://i.imgur.com/q9xY61z.png" height=350 width=350 alt="" class="img-fluid"/>
			</div>
		</div>
	</div>
</section> 



<!-- copyright -->
<section class="copy-right bg-light py-4">
	<div class="container">
		<div class="row">
			<div class="col-lg-7 col-md-9">
				<p class="">Â© 2018 Work. All rights reserved | Design by
					<a href="http://w3layouts.com"> W3layouts.</a>
				</p>
			</div>
			<div class="col-lg-5 col-md-3">
				<ul class="social-iconsv2 agileinfo d-flex">
					<li>
						<a href="#">
							<i class="fab fa-facebook-square"></i>
						</a>
					</li>
					<li>
						<a href="#">
							<i class="fab fa-twitter-square"></i>
						</a>
					</li>
					<li>
						<a href="#">
							<i class="fab fa-google-plus-square"></i>
						</a>
					</li>
					<li>
						<a href="#">
							<i class="fab fa-linkedin"></i>
						</a>
					</li>
				</ul>
			</div>
		</div>
	</div>
</section>
<!-- copyright -->

    <!-- js -->
    <script src="js/jquery-2.2.3.min.js"></script>
    <script src="js/bootstrap.js"></script>
    <!-- //js -->
	
	<!-- dropdown nav -->
    <script>
        $(document).ready(function() {
            $(".dropdown").hover(
                function() {
                    $('.dropdown-menu', this).stop(true, true).slideDown("fast");
                    $(this).toggleClass('open');
                },
                function() {
                    $('.dropdown-menu', this).stop(true, true).slideUp("fast");
                    $(this).toggleClass('open');
                }
            );
        });
    </script>
    <!-- //dropdown nav -->

	<script src="js/smoothscroll.js"></script><!-- Smooth scrolling -->


</body>
</html>