<!--
author: W3layouts
author URL: http://w3layouts.com
License: Creative Commons Attribution 3.0 Unported
License URL: http://creativecommons.org/licenses/by/3.0/
-->
<!DOCTYPE html>
<link rel="shortcut icon" href="https://d1nhio0ox7pgb.cloudfront.net/_img/g_collection_png/standard/256x256/fire.png">
<html lang="en">
<head>
		<title>I'm SunnerLi</title>
		<!-- for-mobile-apps -->
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="keywords" content="Work Responsive web template, Bootstrap Web Templates, Flat Web Templates, Android Compatible web template, 
Smartphone Compatible web template, free webdesigns for Nokia, Samsung, LG, SonyEricsson, Motorola web design" />

    <script>
        addEventListener("load", function () {
            setTimeout(hideURLbar, 0);
        }, false);

        function hideURLbar() {
            window.scrollTo(0, 1);
        }
    </script>
	
	<!-- css files -->
    <link href="css/bootstrap.css" rel='stylesheet' type='text/css' /><!-- bootstrap css -->
    <link href="css/style.css" rel='stylesheet' type='text/css' /><!-- custom css -->
    <link href="css/fontawesome-all.css" rel="stylesheet"><!-- fontawesome css -->
	<!-- //css files -->
	
	<!-- google fonts -->
	<link href="//fonts.googleapis.com/css?family=Mukta:200,300,400,500,600,700,800&amp;subset=devanagari,latin-ext" rel="stylesheet">
	<link href="//fonts.googleapis.com/css?family=Niramit:200,200i,300,300i,400,400i,500,500i,600,600i,700,700i&amp;subset=latin-ext,thai,vietnamese" rel="stylesheet">
	<!-- //google fonts -->
	
</head>
<body>

<!-- header -->
<header class="bg-white py-1">
	<div class="container">
		<nav class="navbar navbar-expand-lg navbar-light">
			<h1>
				<!-- <a class="navbar-brand" href="index.html"><i class="fab fa-python"></i> Sunner</a> -->
			</h1>
			<!-- <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
				<span class="navbar-toggler-icon"></span>
			</button> -->

			<div class="collapse navbar-collapse" id="navbarSupportedContent">
				<ul class="navbar-nav ml-lg-4 mr-auto">
						<!-- <li class="nav-item">
							<a class="nav-link" href="index.html">Home</a>
						</li> -->

						<li class="nav-item dropdown">
							<a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
							  Paper Notes
							</a>
							<div class="dropdown-menu" aria-labelledby="navbarDropdown">
								<a class="dropdown-item" href="paper_note_2019_single.html">2019 (Single)</a>
								<a class="dropdown-item" href="about.html">2018 (Single)</a>
								<a class="dropdown-item" href="paper_note_2018_multiple.html"> 2018 (Multiple)</a>
							</div>
						</li>
						
						<li class="nav-item dropdown">
							<a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
									Repository
							</a>
							<div class="dropdown-menu" aria-labelledby="navbarDropdown">
								<a class="dropdown-item" href="project.html">Project</a>
								<a class="dropdown-item" href="paper_reimplement.html"> Paper Idea Implementation</a>
							</div>
						</li>

						<li class="nav-item dropdown">
							<a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
							  Books
							</a>
							<div class="dropdown-menu" aria-labelledby="navbarDropdown">
								<a class="dropdown-item" href="https://sunnerli.gitbooks.io/test-book/content/">Machine Learning Foundation</a>
								<a class="dropdown-item" href="https://sunnerli.gitbooks.io/test-book-also/content/">Machine Learning Technique</a>
								<a class="dropdown-item" href="https://sunnerli.gitbooks.io/prml/content/">Machine Learning (NCTU)</a>
								<a class="dropdown-item" href="https://sunnerli.gitbooks.io/test-book4/content/"> The Introduction of NLP</a>
							</div>
						</li>

						  <li class="nav-item">
							<a class="nav-link" href="contact.html">Contact</a>
						  </li>
				</ul>
				<div class="header-right">
					<!-- <a href="signin.html" class="signin mr-4"> Sign in <i class="fas fa-sign-in-alt"></i></a> -->
					<a href="index.html" class="contact">Home</a>
				</div>
			</div>
		</nav>
	</div>
</header>
<!-- //header -->

<!-- banner -->
<section class="inner-banner">
	<div class="container">
	</div>
</section>
<!-- //banner -->


<!-- about -->
<section class="about-us py-5">
	<div class="container py-md-3">
		<div class="heading mb-5">
			<h3 class="head text-center">Paper Notes</h3>
			<p class="my-3 head text-center"> 本頁列出了我2019看過paper的相關中文筆記，最新看過的paper會被擺在愈上面，但每一個項目只和一篇論文有關。</p>
		</div>
	</div>
</section>

<!-- 新增templete -->
<!--
<section class="about-us py-5">
	<div class="container py-md-3">
		<div class="row bottom-grids">
			<div class="col-lg-7 col-md-1 px-sm-0">
				<h3 class="my-3"> </h3>       
				<p class="mb-4">   </p>        
				<a href="#">Paper</a>             
				<a href="#">Note</a>           
				<a href="#">Code</a>     
			</div>
			<div class="col-lg7 offset-sm-1 px-lg-1">
					<br></br>
					<br></br>
				<img src="https://i.imgur.com/WTrUdst.png" height=350 width=350 alt="" class="img-fluid"/>
			</div>
		</div>
	</div>
</section> -->

<!-- 從這邊開始往下新增 -->

<section class="about-us py-5">
	<div class="container py-md-3">
		<div class="row bottom-grids">
			<div class="col-lg-7 col-md-1 px-sm-0">
				<h3 class="my-3"> Music Thumbnailing via Neural Attention Modeling of Music Emotion

				</h3>       
				<p class="mb-4"> music thumbnailing的目標是希望找到一個較短且連續的音樂片段，使得這個片段最能代表一首歌。概念是結合emotion recognition來解決music chorus selection的問題。作者引入LSTM和attention layer到CNN中，來做music emotion classification；attention layer則會對每個3秒鐘的chunk評估他的重要性，用31000首歌和相對應的emotion labels來訓練。實驗結果表明有80%的歌曲會把副歌當作是thumbnails。

				</p>        
				<a href="http://mac.citi.sinica.edu.tw/~yang/pub/huang17apsipa.pdf">Paper</a>             
				<a href="https://hackmd.io/WHdadI_pQIiWHkBB9oFuaA">Note</a>              
			</div>
			<div class="col-lg7 offset-sm-1 px-lg-1">
					<br></br>
					<br></br>
				<img src="https://i.imgur.com/Jr2wWRv.png" height=350 width=350 alt="" class="img-fluid"/>
			</div>
		</div>
	</div>
</section>

<section class="about-us py-5">
	<div class="container py-md-3">
		<div class="row bottom-grids">
			<div class="col-lg-7 col-md-1 px-sm-0">
				<h3 class="my-3"> Event Localization in Music Auto-tagging

				</h3>       
				<p class="mb-4"> 本篇想解決的是frame-level的music auto-tagging，即給定一個music clip，我們想知道他的attribute，包刮樂器種類、風格和其他聲學屬性。

				</p>        
				<a href="http://mac.citi.sinica.edu.tw/~yang/pub/liu16mm.pdf">Paper</a>             
				<a href="https://hackmd.io/yTTD0RxaQgWvuHELbLj_Wg">Note</a>           
				<a href="https://github.com/ciaua/clip2frame">Code</a>     
			</div>
			<div class="col-lg7 offset-sm-1 px-lg-1">
					<br></br>
					<br></br>
				<img src="https://i.imgur.com/ScJ5UtV.png" height=350 width=350 alt="" class="img-fluid"/>
			</div>
		</div>
	</div>
</section>

<section class="about-us py-5">
	<div class="container py-md-3">
		<div class="row bottom-grids">
			<div class="col-lg-7 col-md-1 px-sm-0">
				<h3 class="my-3"> Hit Song Prediction for Pop Music by Siamese CNN with Ranking Loss

				</h3>       
				<p class="mb-4"> 這篇paper想要解的問題是hit song prediction。就是在一首歌被發行以前，預測他是否會很紅。傳統方法是把他看成classification(紅或不紅）或regression（紅的分數）的問題，這篇則看成是ranking的問題。作者使用了multi-objective siamese CNN，並結合了Euclidean loss和pairwise ranking loss，來學習不同歌曲之間的排名關係。根據實驗顯示，搭配上A/B sampling可以比其他baseline獲得更高的準確度！

				</p>        
				<a href="https://arxiv.org/abs/1710.10814">Paper</a>             
				<a href="https://hackmd.io/g4eKoSD6QSWalLP2FDBx9A">Note</a>           
				<a href="https://github.com/OckhamsRazor/HSP_CNN">Code</a>     
			</div>
			<div class="col-lg7 offset-sm-1 px-lg-1">
					<br></br>
					<br></br>
				<img src="https://i.imgur.com/KzX9T24.png" height=350 width=350 alt="" class="img-fluid"/>
			</div>
		</div>
	</div>
</section>

<section class="about-us py-5">
	<div class="container py-md-3">
		<div class="row bottom-grids">
			<div class="col-lg-7 col-md-1 px-sm-0">
				<h3 class="my-3"> Transferring GANs: generating images from limited data

				</h3>       
				<p class="mb-4"> 本paper探討的問題是，把domain adaptation的技巧用在GAN的image generation。結果顯示利用pre-trained network的knowledge可以縮短訓練時間，而且如果target data很少的情況下，產生的圖像品質也可大幅度提升！

				</p>        
				<a href="https://arxiv.org/pdf/1805.01677">Paper</a>             
				<a href="https://hackmd.io/DyNQf_RkSLCQ6XH9__HB0Q?view">Note</a>           
				<a href="https://github.com/yaxingwang/Transferring-GANs">Code</a>     
			</div>
			<div class="col-lg7 offset-sm-1 px-lg-1">
					<br></br>
					<br></br>
				<img src="https://i.imgur.com/1Kaj9Dv.png" height=350 width=350 alt="" class="img-fluid"/>
			</div>
		</div>
	</div>
</section>

<section class="about-us py-5">
	<div class="container py-md-3">
		<div class="row bottom-grids">
			<div class="col-lg-7 col-md-1 px-sm-0">
				<h3 class="my-3"> Unsupervised Image Super-Resolution using Cycle-in-Cycle Generative Adversarial Networks

				</h3>       
				<p class="mb-4"> 本篇paper對於super resolution有著不同的看法：low/high resolution的影像配對其實是無法獲得的！在傳統的方法中，低解析度影像其實已經退化，參雜一些noise和blurring。本文提出Cycle-in-cycle的架構來解決unpair super resolution的問題！整個計算過程分成兩步。第一，會先將noisy且blurry的圖片投射到noise-free low-resolution空間中，第二，會把這個intermediate image透過pre-trained deep model投射到high-resolution空間。

				</p>        
				<a href="https://arxiv.org/abs/1809.00437">Paper</a>             
				<a href="https://hackmd.io/0Oh7ymreT4mh9rlUqEfZCw">Note</a>           
				<a href="https://github.com/Junshk/CinCGAN-pytorch">Code (unofficial)</a>     
			</div>
			<div class="col-lg7 offset-sm-1 px-lg-1">
					<br></br>
					<br></br>
				<img src="https://i.imgur.com/L0AoXFk.png" height=350 width=350 alt="" class="img-fluid"/>
			</div>
		</div>
	</div>
</section>

<section class="about-us py-5">
	<div class="container py-md-3">
		<div class="row bottom-grids">
			<div class="col-lg-7 col-md-1 px-sm-0">
				<h3 class="my-3"> MSG-GAN: Multi-Scale Gradient GAN for Stable Image Synthesis

				</h3>       
				<p class="mb-4"> GAN惡名昭彰難用的其中一個原因，是因為訓練過程並不穩定。因為從discriminator傳遞過來的gradient，到generator已經幾乎不具有資訊；本paper提出Multi-scale gradient GAN (MSG-GAN)來解決這個問題，允許discriminator中不同流向、不同尺度的gradient直接傳到generator中，作者實驗在CIFAR10、Oxford102 flowers和CelebA-HQ中皆取得不錯的效果！

				</p>        
				<a href="https://arxiv.org/abs/1903.06048">Paper</a>             
				<a href="https://hackmd.io/6GaiqNanSYi0Kx16MVNwiQ?view">Note</a>           
				<a href="https://github.com/akanimax/BMSG-GAN">Code</a>     
			</div>
			<div class="col-lg7 offset-sm-1 px-lg-1">
					<br></br>
					<br></br>
				<img src="https://i.imgur.com/g2LvsxV.png" height=350 width=350 alt="" class="img-fluid"/>
			</div>
		</div>
	</div>
</section>

<section class="about-us py-5">
	<div class="container py-md-3">
		<div class="row bottom-grids">
			<div class="col-lg-7 col-md-1 px-sm-0">
				<h3 class="my-3"> Maximum Classifier Discrepancy for Unsupervised Domain Adaptation

				</h3>       
				<p class="mb-4"> 本篇paper提出一個unsupervised domain adaptation的方法。傳統上在解這個問題時，通常使用一個domain classifier，並試圖讓source feature和target feature越近越好，但這有兩個缺點：第一，這類的方法並沒有使用task-specific decision boundary的資訊；第二，不同domain有著不同的domain-specific characteristic，一昧地要讓兩個distribution互相靠近是很困難的！因此本文提出了一個新的方法，試圖利用並最大化task-specific decision boundary，最大化兩個classifier 的output來達成目標！

				</p>        
				<a href="https://arxiv.org/abs/1712.02560">Paper</a>             
				<a href="https://hackmd.io/3MmvzkBcQdyJr2rozCDN-Q?view">Note</a>           
				<a href="https://github.com/mil-tokyo/MCD_DA">Code</a>     
			</div>
			<div class="col-lg7 offset-sm-1 px-lg-1">
					<br></br>
					<br></br>
				<img src="https://raw.githubusercontent.com/mil-tokyo/MCD_DA/master/docs/overview.png" height=350 width=350 alt="" class="img-fluid"/>
			</div>
		</div>
	</div>
</section>

<section class="about-us py-5">
	<div class="container py-md-3">
		<div class="row bottom-grids">
			<div class="col-lg-7 col-md-1 px-sm-0">
				<h3 class="my-3"> Self-Supervised Feature Learning for Semantic Segmentation of Overhead Imagery

				</h3>       
				<p class="mb-4"> 這篇paper想處理的對象是航空影像(overhead image)，然而針對這樣的影像做semantic segmentation是個巨大的挑戰，因為根本沒有GT，而且和地面照有著很大的domain gap。作者提出一種self-supervised的方法來對overhead imagery做semantic segmentation，並透過adversarial training有了更好的pre-trained feature。

				</p>        
				<a href="http://bmvc2018.org/contents/papers/0345.pdf">Paper</a>             
				<a href="https://hackmd.io/WIGVOhcyQmmzZoVjzygVLQ">Note</a>           
				<a href="https://github.com/suriyasingh/Self-supervision-for-segmenting-overhead-imagery">Code</a>     
			</div>
			<div class="col-lg7 offset-sm-1 px-lg-1">
					<br></br>
					<br></br>
				<img src="https://i.imgur.com/fm6f4is.png" height=350 width=350 alt="" class="img-fluid"/>
			</div>
		</div>
	</div>
</section>

<section class="about-us py-5">
	<div class="container py-md-3">
		<div class="row bottom-grids">
			<div class="col-lg-7 col-md-1 px-sm-0">
				<h3 class="my-3"> Semantic Image Synthesis with Spatially-Adaptive Normalization

				</h3>       
				<p class="mb-4"> 本篇提出了spatially-adaptive normalization，進而結合進pix2pixHD，形成一個新的模型為GauGAN，用來解決image synthesize的問題。傳統的CNN大多使用疊起來的(conv, BN, ReLU)運算組合，但這樣的做法會把輸入的semantic information"洗掉"，因此作者提出spatially-adaptive版本的可學習轉換，來解決這個爭議。上圖是一個簡單的結果，如果先求出最左邊column的latent representation，再透過SPADE生成圖片的話，style就會有所不同。

				</p>        
				<a href="https://arxiv.org/abs/1903.07291">Paper</a>             
				<a href="https://hackmd.io/r-u6WR8fRO6uPK7HSC3nZQ">Note</a>           
				<a href="">Code (TBC)</a>     
			</div>
			<div class="col-lg7 offset-sm-1 px-lg-1">
					<br></br>
					<br></br>
				<img src="https://i.imgur.com/N2zZNei.jpg" height=350 width=350 alt="" class="img-fluid"/>
			</div>
		</div>
	</div>
</section>

<section class="about-us py-5">
	<div class="container py-md-3">
		<div class="row bottom-grids">
			<div class="col-lg-7 col-md-1 px-sm-0">
				<h3 class="my-3"> GANimation: Anatomically-aware Facial Animation from a Single Image

				</h3>       
				<p class="mb-4"> 先前已有研究來做臉部表情合成(facial expression synthesis)，最知名的例子便是StarGAN，但僅能學出離散型別的表情(因為在StarGAN中attribute是離散變量)。本篇paper提出基於Action Units(AU)的臉部表情合成方法，AU定義了人臉表情，且是分布在一個低微度且連續的manifold中，作者指出僅需使用有AU標註的影像進行非監督式訓練，即可達到更好的效果，可渲染出更多樣的表情，包括臉部肌肉的彈性度。

				</p>        
				<a href="https://arxiv.org/pdf/1807.09251.pdf">Paper</a>             
				<a href="https://hackmd.io/uzvBHQ6HRyWcjJLI345a5g">Note</a>           
				<a href="https://github.com/albertpumarola/GANimation">Code</a>     
			</div>
			<div class="col-lg7 offset-sm-1 px-lg-1">
					<br></br>
					<br></br>
				<img src="https://i.imgur.com/3mEf8z8.png" height=350 width=350 alt="" class="img-fluid"/>
			</div>
		</div>
	</div>
</section>

<section class="about-us py-5">
	<div class="container py-md-3">
		<div class="row bottom-grids">
			<div class="col-lg-7 col-md-1 px-sm-0">
				<h3 class="my-3"> Identifying Analogies Across Domains

				</h3>       
				<p class="mb-4"> 雖然現在unsupervised identifying analogy的研究已經可以達到不錯的效果，但轉換圖像的visual fidelity並不足夠識別在另外一個domain中的matching sample。本篇paper提出AN-GAN，採用一種名為matching-by-synthesis的思想，把轉換的過程分成兩部：domain alignment和learning the mapping function。

				</p>        
				<a href="https://openreview.net/pdf?id=BkN_r2lR-">Paper</a>             
				<a href="https://hackmd.io/Ao5qK-nURTK6vx-lNT1UTw">Note</a>               
			</div>
			<div class="col-lg7 offset-sm-1 px-lg-1">
					<br></br>
					<br></br>
				<img src="https://i.imgur.com/EtlwxhI.png" height=350 width=350 alt="" class="img-fluid"/>
			</div>
		</div>
	</div>
</section>


<section class="about-us py-5">
	<div class="container py-md-3">
		<div class="row bottom-grids">
			<div class="col-lg-7 col-md-1 px-sm-0">
				<h3 class="my-3"> A Closer Look at Few-shot Classification
				</h3>       
				<p class="mb-4"> 由於不同的few-shot algorithm有不同的implementation detail，且比較的方式也不太一樣，因此很難公平的比較哪一個方法比較好。本篇paper提出：第一，公平的分析與比較得知，如果用的backbone network較深，且domain difference較少的話，不同的方法都可顯著的降低classification gap；第二，稍微對網路做一些改良，便可在mini-ImageNet和CUB兩個資料集更加提升SOTA；最後，對於cross-domain的few shot classification問題，提出一個新的實驗設定。

				</p>        
				<a href="https://openreview.net/pdf?id=HkxLXnAcFQ">Paper</a>             
				<a href="https://hackmd.io/jmipjbf0TseG_lxd8baWQA?view">Note</a>           
				<a href="https://github.com/wyharveychen/CloserLookFewShot">Code</a>     
			</div>
			<div class="col-lg7 offset-sm-1 px-lg-1">
					<br></br>
					<br></br>
				<img src="https://i.imgur.com/39AVmGL.png" height=350 width=350 alt="" class="img-fluid"/>
			</div>
		</div>
	</div>
</section>

<section class="about-us py-5">
	<div class="container py-md-3">
		<div class="row bottom-grids">
			<div class="col-lg-7 col-md-1 px-sm-0">
				<h3 class="my-3"> DeepFool: a simple and accurate method to fool deep neural networks
				</h3>       
				<p class="mb-4"> 對於以前adversarial attack的方法，並沒有一個很精準的方法可以計算很小的perturbations。本篇paper提出DeepFool，可以較有效率並精準的計算最小的perturbation，以欺騙classifier。

				</p>        
				<a href="https://arxiv.org/pdf/1511.04599.pdf">Paper</a>             
				<a href="https://hackmd.io/jwfnZWTkQ86R4UNfTwfk2w?view">Note</a>           
				<a href="https://github.com/LTS4/DeepFool/tree/master/Python">Code</a>     
			</div>
			<div class="col-lg7 offset-sm-1 px-lg-1">
					<br></br>
					<br></br>
				<img src="https://i.imgur.com/Rz5rdgh.png" height=350 width=350 alt="" class="img-fluid"/>
			</div>
		</div>
	</div>
</section>

<section class="about-us py-5">
	<div class="container py-md-3">
		<div class="row bottom-grids">
			<div class="col-lg-7 col-md-1 px-sm-0">
				<h3 class="my-3"> Image Super-Resolution as a Defense Against Adversarial Attacks
				</h3>       
				<p class="mb-4"> CNN對於含有adversarial noise pattern的輸入可能較容易被混淆，本paper提出一種防禦機制來緩解adversarial pertubation造成的性能丟失問題。在本研究中，image restoration network會把off-the-manifold adversarial sample拉回natural image manifold中，且此方法不需要修改classifier的參數，也不需要額外的過程去偵測哪些圖片是adversarial example。

				</p>        
				<a href="https://arxiv.org/abs/1901.01677">Paper</a>             
				<a href="https://hackmd.io/zfJ_8XSSQ8iIrEJX3nAjXw">Note</a>           
				<a href="https://github.com/aamir-mustafa/super-resolution-adversarial-defense">Code</a>     
			</div>
			<div class="col-lg7 offset-sm-1 px-lg-1">
					<br></br>
					<br></br>
				<img src="https://i.imgur.com/SY7nZka.png" height=350 width=350 alt="" class="img-fluid"/>
			</div>
		</div>
	</div>
</section>

<section class="about-us py-5">
	<div class="container py-md-3">
		<div class="row bottom-grids">
			<div class="col-lg-7 col-md-1 px-sm-0">
				<h3 class="my-3"> EdgeConnect: Generative Image Inpainting with Adversarial Edge Learning
				</h3>       
				<p class="mb-4"> 先前做image inpainting的研究，做出來的結果普遍很平滑或是模糊。本論文提出EngeConnect，是一種兩階段的對抗是模型，由edge generator和image completion network組成，網路會把幻想出來的edge當作prior來渲染，實驗在CelebA和Places2資料集中取得了SOTA。

				</p>        
				<a href="https://arxiv.org/abs/1901.00212">Paper</a>             
				<a href="https://hackmd.io/9npdnYG2QzGJtthZIFPKiA?view">Note</a>           
				<a href="https://github.com/knazeri/edge-connect">Code</a>     
			</div>
			<div class="col-lg7 offset-sm-1 px-lg-1">
					<br></br>
					<br></br>
				<img src="https://i.imgur.com/BsQm5c3.png" height=350 width=350 alt="" class="img-fluid"/>
			</div>
		</div>
	</div>
</section>

<section class="about-us py-5">
	<div class="container py-md-3">
		<div class="row bottom-grids">
			<div class="col-lg-7 col-md-1 px-sm-0">
				<h3 class="my-3"> CCNet: Criss-Cross Attention for Semantic Segmentation
                </h3>       
				<p class="mb-4">  long-range dependency在visual understanding裡也同樣重要，但傳統CNN的respected field是有限的，因此本文提出Criss-Cross Network (CCNet)。網路中含有criss-cross attention module，該module收集了對每個pixel十字架路徑上的contextual information。比起He的non-local network，CCNet不僅實作上較為GPU-friendly（快了11倍），計算上也較有效率（FLOPs為15%） </p>        
				<a href="https://arxiv.org/abs/1811.11721">Paper</a>             
				<a href="https://hackmd.io/QDIdfKtFS7-5864v6Xm2kA">Note</a>           
				<a href="https://github.com/speedinghzl/CCNet">Code</a>     
			</div>
			<div class="col-lg7 offset-sm-1 px-lg-1">
					<br></br>
					<br></br>
				<img src="https://i.imgur.com/4sNp6i4.png" height=350 width=350 alt="" class="img-fluid"/>
			</div>
		</div>
	</div>
</section> 

<section class="about-us py-5">
	<div class="container py-md-3">
		<div class="row bottom-grids">
			<div class="col-lg-7 col-md-1 px-sm-0">
				<h3 class="my-3"> Adversarial Discriminative Domain Adaptation
                </h3>       
				<p class="mb-4">  對抗式學習可以被拿來改善recognition task的performance，消除domain shift或dataset bias造成的性能損失。先前的研究可分為兩者討論：

                    Prior generative approach：讓generator的部份資料分佈儘量一致，但這類型的方法沒辦法被用在domain shift很大的情況
                    Prior discriminative approach: 讓discriminator儘量保持一致，這類型的方法大多是強迫tie weight(share weight)，也沒有用到GAN 的概念
                    本研究結合了discriminative model, weight sharing和GAN loss的想法，提出了Adversarial Discriminative Domain Adaptation框架(ADDA)，是一種非監督式的domain adaptation方法。 </p>        
				<a href="https://arxiv.org/abs/1702.05464">Paper </a>             
				<a href="https://hackmd.io/3Fa2I-coRQqBMH42XDo0QA">Note</a>           
				<a href="https://github.com/erictzeng/adda">Code</a>     
			</div>
			<div class="col-lg7 offset-sm-1 px-lg-1">
					<br></br>
					<br></br>
				<img src="https://i.imgur.com/yLsW4Nx.png" height=350 width=350 alt="" class="img-fluid"/>
			</div>
		</div>
    </div>
    
<section class="about-us py-5">
	<div class="container py-md-3">
		<div class="row bottom-grids">
			<div class="col-lg-7 col-md-1 px-sm-0">
				<h3 class="my-3"> InstaGAN: Instance-aware Image-to-Image Translation
                </h3>       
				<p class="mb-4"> 在image-to-image translation的任務中，先前的方法會在較為複雜的考驗中失敗，物體的形狀很難被保留，例如有多個instance要轉換的場景。本研究利用instance information，提出了instance-aware GAN (InstaGAN)，並引入了context preserving loss，迫使網路在target instance以外的範圍學習對等映射(輸入=輸出)

                </p>        
				<a href="https://arxiv.org/abs/1812.10889">Paper </a>             
				<a href="https://hackmd.io/QYDwy8mBTweaZY2DSdeYaQ">Note</a>           
				<a href="https://github.com/sangwoomo/instagan">Code</a>     
			</div>
			<div class="col-lg7 offset-sm-1 px-lg-1">
					<br></br>
					<br></br>
				<img src="https://i.imgur.com/q9xY61z.png" height=350 width=350 alt="" class="img-fluid"/>
			</div>
		</div>
	</div>
</section> 



<!-- copyright -->
<section class="copy-right bg-light py-4">
	<div class="container">
		<div class="row">
			<div class="col-lg-7 col-md-9">
				<p class="">© 2018 Work. All rights reserved | Design by
					<a href="http://w3layouts.com"> W3layouts.</a>
				</p>
			</div>
			<div class="col-lg-5 col-md-3">
				<ul class="social-iconsv2 agileinfo d-flex">
					<li>
						<a href="#">
							<i class="fab fa-facebook-square"></i>
						</a>
					</li>
					<li>
						<a href="#">
							<i class="fab fa-twitter-square"></i>
						</a>
					</li>
					<li>
						<a href="#">
							<i class="fab fa-google-plus-square"></i>
						</a>
					</li>
					<li>
						<a href="#">
							<i class="fab fa-linkedin"></i>
						</a>
					</li>
				</ul>
			</div>
		</div>
	</div>
</section>
<!-- copyright -->

    <!-- js -->
    <script src="js/jquery-2.2.3.min.js"></script>
    <script src="js/bootstrap.js"></script>
    <!-- //js -->
	
	<!-- dropdown nav -->
    <script>
        $(document).ready(function() {
            $(".dropdown").hover(
                function() {
                    $('.dropdown-menu', this).stop(true, true).slideDown("fast");
                    $(this).toggleClass('open');
                },
                function() {
                    $('.dropdown-menu', this).stop(true, true).slideUp("fast");
                    $(this).toggleClass('open');
                }
            );
        });
    </script>
    <!-- //dropdown nav -->

	<script src="js/smoothscroll.js"></script><!-- Smooth scrolling -->


</body>
</html>